{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0f793f6b",
      "metadata": {
        "id": "0f793f6b"
      },
      "source": [
        "# GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92aa9155",
      "metadata": {
        "id": "92aa9155"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "print(tf.__version__)\n",
        "\n",
        "tf.config.experimental.list_physical_devices(device_type=None)\n",
        "\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "  try:\n",
        "    # Currently, memory growth needs to be the same across GPUs\n",
        "    for gpu in gpus:\n",
        "      tf.config.experimental.set_memory_growth(gpu, True)\n",
        "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
        "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
        "  except RuntimeError as e:\n",
        "    # Memory growth must be set before GPUs have been initialized\n",
        "    print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b66bb40",
      "metadata": {
        "id": "7b66bb40"
      },
      "source": [
        "# Original BILSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0263363",
      "metadata": {
        "id": "e0263363"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "\n",
        "# =======================\n",
        "# 1Ô∏è‚É£ GPU Memory Optimization\n",
        "# =======================\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        print(\"‚úÖ GPU Memory Growth Enabled\")\n",
        "    except RuntimeError as e:\n",
        "        print(e)\n",
        "\n",
        "# Enable mixed precision\n",
        "tf.keras.mixed_precision.set_global_policy(\"mixed_float16\")\n",
        "\n",
        "# =======================\n",
        "# 2Ô∏è‚É£ Load Features with Sliding Windows\n",
        "# =======================\n",
        "base_path = \"/mnt/d/Mass Projects/Video_Summ/new_dataset_features_npy1\"\n",
        "train_path = os.path.join(base_path, \"train\")\n",
        "valid_path = os.path.join(base_path, \"valid\")\n",
        "\n",
        "SEQ_LEN = 150     # ‚úÖ smaller window to avoid OOM\n",
        "STRIDE = 125      # ‚úÖ overlap to preserve temporal context\n",
        "FEATURE_DIM = 2048\n",
        "\n",
        "def load_features(directory):\n",
        "    all_windows = []\n",
        "    video_files = sorted(os.listdir(directory))\n",
        "    for file in video_files:\n",
        "        file_path = os.path.join(directory, file)\n",
        "        features = np.load(file_path)  # shape: (1750, 2048)\n",
        "\n",
        "        # Create sliding windows\n",
        "        for start in range(0, len(features) - SEQ_LEN + 1, STRIDE):\n",
        "            window = features[start:start+SEQ_LEN]\n",
        "            all_windows.append(window)\n",
        "    return np.array(all_windows, dtype=np.float32)  # shape: (num_windows, SEQ_LEN, FEATURE_DIM)\n",
        "\n",
        "print(\"üì• Loading dataset...\")\n",
        "train_features = load_features(train_path)\n",
        "valid_features = load_features(valid_path)\n",
        "print(\"Train windows:\", train_features.shape)\n",
        "print(\"Valid windows:\", valid_features.shape)\n",
        "\n",
        "NUM_EPOCHS = 100\n",
        "BATCH_SIZE = 1\n",
        "LEARNING_RATE = 1e-7\n",
        "MODEL_SAVE_PATH = \"/mnt/d/Mass Projects/Video_Summ/RESULTS/Models_2/SUMME/video_summarization_4-heads_15k.keras\"\n",
        "os.makedirs(os.path.dirname(MODEL_SAVE_PATH), exist_ok=True)\n",
        "\n",
        "# =======================\n",
        "# 3Ô∏è‚É£ Define BiLSTM + Multi-Head Attention Model\n",
        "# =======================\n",
        "class BiLSTMAttentionModel(models.Model):\n",
        "    def __init__(self, feature_dim, num_heads=4, lstm_units=64, **kwargs):\n",
        "        super(BiLSTMAttentionModel, self).__init__(**kwargs)\n",
        "        self.feature_dim = feature_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.lstm_units = lstm_units\n",
        "\n",
        "        self.bilstm = layers.Bidirectional(\n",
        "            layers.LSTM(lstm_units, return_sequences=True)\n",
        "        )\n",
        "        self.attention = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=feature_dim // num_heads\n",
        "        )\n",
        "        self.reconstruction_layer = layers.TimeDistributed(\n",
        "            layers.Dense(feature_dim, activation=\"linear\")\n",
        "        )\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.bilstm(inputs)\n",
        "        x = self.attention(x, x)\n",
        "        reconstructed = self.reconstruction_layer(x)\n",
        "        return reconstructed\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(BiLSTMAttentionModel, self).get_config()\n",
        "        config.update({\n",
        "            \"feature_dim\": self.feature_dim,\n",
        "            \"num_heads\": self.num_heads,\n",
        "            \"lstm_units\": self.lstm_units\n",
        "        })\n",
        "        return config\n",
        "\n",
        "    @classmethod\n",
        "    def from_config(cls, config):\n",
        "        return cls(**config)\n",
        "\n",
        "# =======================\n",
        "# 4Ô∏è‚É£ Build + Compile Model\n",
        "# =======================\n",
        "model = BiLSTMAttentionModel(feature_dim=FEATURE_DIM)\n",
        "model.build(input_shape=(None, SEQ_LEN, FEATURE_DIM))\n",
        "\n",
        "model.compile(\n",
        "    optimizer=optimizers.Adam(learning_rate=LEARNING_RATE),\n",
        "    loss=\"mse\",\n",
        "    metrics=[\"mae\"]\n",
        ")\n",
        "\n",
        "# =======================\n",
        "# 5Ô∏è‚É£ Training\n",
        "# =======================\n",
        "print(\"üöÄ Starting Training...\")\n",
        "history = model.fit(\n",
        "    train_features, train_features,\n",
        "    validation_data=(valid_features, valid_features),\n",
        "    epochs=NUM_EPOCHS,\n",
        "    batch_size=BATCH_SIZE\n",
        ")\n",
        "\n",
        "model.save(MODEL_SAVE_PATH)\n",
        "print(f\"‚úÖ Model saved at {MODEL_SAVE_PATH}\")\n",
        "\n",
        "# =======================\n",
        "# 6Ô∏è‚É£ Evaluation\n",
        "# =======================\n",
        "with tf.keras.utils.custom_object_scope({\"BiLSTMAttentionModel\": BiLSTMAttentionModel}):\n",
        "    model = tf.keras.models.load_model(MODEL_SAVE_PATH)\n",
        "\n",
        "print(\"üîÑ Model loaded for evaluation.\")\n",
        "\n",
        "test_video = valid_features[0:1]  # (1, SEQ_LEN, 2048)\n",
        "reconstructed_video = model.predict(test_video)\n",
        "print(\"Reconstructed Features Shape:\", reconstructed_video.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5143bf3",
      "metadata": {
        "id": "e5143bf3"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "482aff39",
      "metadata": {
        "id": "482aff39"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import scipy.io\n",
        "import ruptures as rpt\n",
        "import pandas as pd\n",
        "import gc\n",
        "\n",
        "# ========= 1. Load Model =========\n",
        "class BiLSTMAttentionModel(tf.keras.Model):\n",
        "    def __init__(self, feature_dim=2048, num_heads=2, lstm_units=128, **kwargs):\n",
        "        super(BiLSTMAttentionModel, self).__init__(**kwargs)\n",
        "        self.bilstm = tf.keras.layers.Bidirectional(\n",
        "            tf.keras.layers.LSTM(lstm_units, return_sequences=True))\n",
        "        self.attention = tf.keras.layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=feature_dim // num_heads)\n",
        "        self.reconstruction_layer = tf.keras.layers.TimeDistributed(\n",
        "            tf.keras.layers.Dense(feature_dim, activation=\"linear\"))\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.bilstm(inputs)\n",
        "        x = self.attention(x, x)\n",
        "        return self.reconstruction_layer(x)\n",
        "\n",
        "# MODEL_PATH = \"/mnt/d/Mass Projects/Video_Summ/RESULTS/MODELS/bilstm_multi_2-heads_60k.keras\"\n",
        "MODEL_PATH = \"/mnt/d/Mass Projects/Video_Summ/RESULTS/Final/Models/bilstm_multi_4-heads_60k_2.keras\"\n",
        "with tf.keras.utils.custom_object_scope({\"BiLSTMAttentionModel\": BiLSTMAttentionModel}):\n",
        "    model = tf.keras.models.load_model(MODEL_PATH)\n",
        "print(\"\\n‚úÖ Model loaded successfully\")\n",
        "\n",
        "# ========= 2. Helper Functions =========\n",
        "def get_segments_from_indices(indices):\n",
        "    if not indices:\n",
        "        return []\n",
        "    indices = sorted(set(indices))\n",
        "    segments, start = [], indices[0]\n",
        "    for i in range(1, len(indices)):\n",
        "        if indices[i] != indices[i - 1] + 1:\n",
        "            segments.append((start, indices[i - 1]))\n",
        "            start = indices[i]\n",
        "    segments.append((start, indices[-1]))\n",
        "    return segments\n",
        "\n",
        "def expand_segment(seg):\n",
        "    return list(range(seg[0], seg[1] + 1))\n",
        "\n",
        "def format_segments(segments):\n",
        "    return [f\"({s})\" if s == e else f\"({s}‚Äì{e})\" for s, e in segments]\n",
        "\n",
        "def print_segments_columnwise(segments, items_per_line=10):\n",
        "    for i in range(0, len(segments), items_per_line):\n",
        "        print(\"  \" + \"  \".join(segments[i:i + items_per_line]))\n",
        "\n",
        "def calculate_segment_f1(user_segments, model_segments):\n",
        "    tp = 0\n",
        "    matched = []\n",
        "    for m_seg in model_segments:\n",
        "        m_range = set(expand_segment(m_seg))\n",
        "        for u_seg in user_segments:\n",
        "            u_range = set(expand_segment(u_seg))\n",
        "            if m_range & u_range:\n",
        "                tp += 1\n",
        "                matched.append(m_seg)\n",
        "                break\n",
        "    precision = tp / len(model_segments) if model_segments else 0\n",
        "    recall = tp / len(user_segments) if user_segments else 0\n",
        "    f1 = 2 * precision * recall / (precision + recall) if precision + recall else 0\n",
        "    return f1, precision, recall, matched\n",
        "\n",
        "def detect_kts_segments(features, penalty=500):\n",
        "    algo = rpt.KernelCPD(kernel=\"linear\").fit(features)\n",
        "    change_points = algo.predict(pen=penalty)\n",
        "    change_points = [int(cp) for cp in change_points]\n",
        "    scene_segments = []\n",
        "    start_frame = 0\n",
        "    for cp in change_points:\n",
        "        scene_segments.append((start_frame, cp - 1))\n",
        "        start_frame = cp\n",
        "    if scene_segments[-1][1] < features.shape[0] - 1:\n",
        "        scene_segments.append((start_frame, features.shape[0] - 1))\n",
        "    return scene_segments\n",
        "\n",
        "def knapsack(values, weights, capacity):\n",
        "    n = len(values)\n",
        "    dp = [[0 for _ in range(int(capacity * 100) + 1)] for _ in range(n + 1)]\n",
        "    for i in range(1, n + 1):\n",
        "        for w in range(int(capacity * 100) + 1):\n",
        "            weight = int(weights[i - 1] * 100)\n",
        "            if weight <= w:\n",
        "                dp[i][w] = max(values[i - 1] + dp[i - 1][w - weight], dp[i - 1][w])\n",
        "            else:\n",
        "                dp[i][w] = dp[i - 1][w]\n",
        "    selected = []\n",
        "    w = int(capacity * 100)\n",
        "    for i in range(n, 0, -1):\n",
        "        if dp[i][w] != dp[i - 1][w]:\n",
        "            selected.append(i - 1)\n",
        "            w -= int(weights[i - 1] * 100)\n",
        "    return selected[::-1]\n",
        "\n",
        "# ========= 3. Process Videos =========\n",
        "video_list = [\n",
        "    \"Jumps\", \"Base Jumping\", \"Air_Force_One\", \"Bearpark_climbing\", \"Bike Polo\",\n",
        "    \"Bus_in_Rock_Tunnel\", \"car_over_camera\", \"Car_railcrossing\", \"Cockpit_Landing\", \"Cooking\",\n",
        "    \"Eiffel Tower\", \"Excavators river crossing\", \"Fire Domino\", \"Kids_playing_in_leaves\",\n",
        "    \"Notre_Dame\", \"Paintball\", \"paluma_jump\", \"playing_ball\", \"Playing_on_water_slide\",\n",
        "    \"Saving dolphines\", \"Scuba\", \"St Maarten Landing\", \"Statue of Liberty\", \"Valparaiso_Downhill\"\n",
        "]\n",
        "\n",
        "FEATURES_DIR = \"/mnt/d/Mass Projects/Video_Summ/extracted_features/\"\n",
        "MAT_DIR = \"/mnt/d/Mass Projects/Video_Summ/mat/\"\n",
        "CHUNK_SIZE = 500\n",
        "PENALTY = 500\n",
        "FPS = 25\n",
        "SUMMARY_EXCEL = \"/mnt/d/Mass Projects/Video_Summ/RESULTS/Final/Results/SUMME/bilstm_multi_4-heads_60k_2.xlsx\"\n",
        "\n",
        "with pd.ExcelWriter(SUMMARY_EXCEL, engine=\"xlsxwriter\") as writer:\n",
        "    summary_data = []\n",
        "\n",
        "    for VIDEO_NAME in video_list:\n",
        "        print(f\"\\n==============================\\nüöÄ Processing video: {VIDEO_NAME}\\n==============================\")\n",
        "\n",
        "        feats_path = os.path.join(FEATURES_DIR, f\"{VIDEO_NAME}.npy\")\n",
        "        mat_path = os.path.join(MAT_DIR, f\"{VIDEO_NAME}.mat\")\n",
        "        if not os.path.exists(feats_path) or not os.path.exists(mat_path):\n",
        "            print(\"‚ùå Skipping, missing file.\")\n",
        "            continue\n",
        "\n",
        "        raw_feats = np.load(feats_path)\n",
        "        num_frames = raw_feats.shape[0]\n",
        "        video_feats = raw_feats[np.newaxis, ...]\n",
        "\n",
        "        recon = np.zeros_like(video_feats)\n",
        "        for i in range((num_frames + CHUNK_SIZE - 1) // CHUNK_SIZE):\n",
        "            s, e = i * CHUNK_SIZE, min((i + 1) * CHUNK_SIZE, num_frames)\n",
        "            recon[:, s:e, :] = model.predict(video_feats[:, s:e, :], verbose=0)\n",
        "        print(\"‚úÖ Features reconstructed\")\n",
        "\n",
        "        errs = np.mean(np.abs(video_feats - recon), axis=2).flatten()\n",
        "        imp_scores = (errs - errs.min()) / (errs.max() - errs.min())\n",
        "\n",
        "        model_segments = detect_kts_segments(raw_feats, penalty=PENALTY)\n",
        "        segment_durations = [(end - start + 1) / FPS for start, end in model_segments]\n",
        "        segment_scores = [np.mean(imp_scores[start:end + 1]) for start, end in model_segments]\n",
        "\n",
        "        total_duration = num_frames / FPS\n",
        "        summary_duration = total_duration * 0.15\n",
        "        selected_indices = knapsack(segment_scores, segment_durations, summary_duration)\n",
        "        selected_model_segments = [model_segments[i] for i in selected_indices]\n",
        "\n",
        "        mat = scipy.io.loadmat(mat_path)\n",
        "        user_scores = mat['user_score']\n",
        "        num_users = user_scores.shape[1]\n",
        "        all_user_metrics = []\n",
        "\n",
        "        for u in range(num_users):\n",
        "            usr = user_scores[:, u]\n",
        "            nonzero_indices = np.where(usr > 0)[0]\n",
        "            user_segments = get_segments_from_indices(nonzero_indices.tolist())\n",
        "\n",
        "            f1, precision, recall, _ = calculate_segment_f1(user_segments, selected_model_segments)\n",
        "            all_user_metrics.append((u + 1, f1, precision, recall))\n",
        "\n",
        "        df = pd.DataFrame(all_user_metrics, columns=[\"User\", \"F1 Score\", \"Precision\", \"Recall\"])\n",
        "        df.to_excel(writer, sheet_name=VIDEO_NAME[:31], index=False)\n",
        "\n",
        "        summary_data.append({\n",
        "            \"Video Name\": VIDEO_NAME,\n",
        "            \"KTS Segments\": len(model_segments),\n",
        "            \"Knapsack Selected\": len(selected_model_segments),\n",
        "            \"Penalty\": PENALTY,\n",
        "            \"Min Precision\": df[\"Precision\"].min(),\n",
        "            \"Avg Precision\": df[\"Precision\"].mean(),\n",
        "            \"Max Precision\": df[\"Precision\"].max(),\n",
        "            \"Min Recall\": df[\"Recall\"].min(),\n",
        "            \"Avg Recall\": df[\"Recall\"].mean(),\n",
        "            \"Max Recall\": df[\"Recall\"].max(),\n",
        "            \"Min F1\": df[\"F1 Score\"].min(),\n",
        "            \"Avg F1\": df[\"F1 Score\"].mean(),\n",
        "            \"Max F1\": df[\"F1 Score\"].max(),\n",
        "        })\n",
        "\n",
        "        del video_feats, recon\n",
        "        gc.collect()\n",
        "        tf.keras.backend.clear_session()\n",
        "\n",
        "    pd.DataFrame(summary_data).to_excel(writer, sheet_name=\"Summary\", index=False)\n",
        "    print(f\"\\n‚úÖ All results saved to: {SUMMARY_EXCEL}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91b9042c",
      "metadata": {
        "id": "91b9042c"
      },
      "source": [
        "# TVSUM EVALUATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13b99e22",
      "metadata": {
        "id": "13b99e22"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import h5py\n",
        "import gc\n",
        "import ruptures as rpt\n",
        "\n",
        "# ========= 1. Load Model =========\n",
        "class BiLSTMAttentionModel(tf.keras.Model):\n",
        "    def __init__(self, feature_dim=2048, num_heads=8, lstm_units=128, **kwargs):\n",
        "        super(BiLSTMAttentionModel, self).__init__(**kwargs)\n",
        "        self.bilstm = tf.keras.layers.Bidirectional(\n",
        "            tf.keras.layers.LSTM(lstm_units, return_sequences=True))\n",
        "        self.attention = tf.keras.layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=feature_dim // num_heads)\n",
        "        self.reconstruction_layer = tf.keras.layers.TimeDistributed(\n",
        "            tf.keras.layers.Dense(feature_dim, activation=\"linear\"))\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.bilstm(inputs)\n",
        "        x = self.attention(x, x)\n",
        "        return self.reconstruction_layer(x)\n",
        "\n",
        "MODEL_PATH = \"/mnt/d/Mass Projects/Video_Summ/RESULTS/MODELS/bilstm_multi_8-heads_60k.keras\"\n",
        "with tf.keras.utils.custom_object_scope({\"BiLSTMAttentionModel\": BiLSTMAttentionModel}):\n",
        "    model = tf.keras.models.load_model(MODEL_PATH)\n",
        "print(\"\\n‚úÖ Model loaded successfully\")\n",
        "\n",
        "# ========= 2. Helper Functions =========\n",
        "def get_segments_from_indices(indices):\n",
        "    if not indices:\n",
        "        return []\n",
        "    indices = sorted(set(indices))\n",
        "    segments, start = [], indices[0]\n",
        "    for i in range(1, len(indices)):\n",
        "        if indices[i] != indices[i - 1] + 1:\n",
        "            segments.append((start, indices[i - 1]))\n",
        "            start = indices[i]\n",
        "    segments.append((start, indices[-1]))\n",
        "    return segments\n",
        "\n",
        "def expand_segment(seg):\n",
        "    return list(range(seg[0], seg[1] + 1))\n",
        "\n",
        "def calculate_segment_f1(user_segments, model_segments):\n",
        "    tp = 0\n",
        "    for m_seg in model_segments:\n",
        "        m_range = set(expand_segment(m_seg))\n",
        "        for u_seg in user_segments:\n",
        "            u_range = set(expand_segment(u_seg))\n",
        "            if m_range & u_range:\n",
        "                tp += 1\n",
        "                break\n",
        "    precision = tp / len(model_segments) if model_segments else 0\n",
        "    recall = tp / len(user_segments) if user_segments else 0\n",
        "    f1 = 2 * precision * recall / (precision + recall) if precision + recall else 0\n",
        "    return f1, precision, recall\n",
        "\n",
        "def detect_kts_segments(features, penalty=500):\n",
        "    algo = rpt.KernelCPD(kernel=\"linear\").fit(features)\n",
        "    change_points = algo.predict(pen=penalty)\n",
        "    change_points = [int(cp) for cp in change_points]\n",
        "    scene_segments = []\n",
        "    start_frame = 0\n",
        "    for cp in change_points:\n",
        "        scene_segments.append((start_frame, cp - 1))\n",
        "        start_frame = cp\n",
        "    if scene_segments[-1][1] < features.shape[0] - 1:\n",
        "        scene_segments.append((start_frame, features.shape[0] - 1))\n",
        "    return scene_segments\n",
        "\n",
        "def knapsack(values, weights, capacity):\n",
        "    n = len(values)\n",
        "    dp = [[0 for _ in range(int(capacity * 100) + 1)] for _ in range(n + 1)]\n",
        "    for i in range(1, n + 1):\n",
        "        for w in range(int(capacity * 100) + 1):\n",
        "            weight = int(weights[i - 1] * 100)\n",
        "            if weight <= w:\n",
        "                dp[i][w] = max(values[i - 1] + dp[i - 1][w - weight], dp[i - 1][w])\n",
        "            else:\n",
        "                dp[i][w] = dp[i - 1][w]\n",
        "    selected = []\n",
        "    w = int(capacity * 100)\n",
        "    for i in range(n, 0, -1):\n",
        "        if dp[i][w] != dp[i - 1][w]:\n",
        "            selected.append(i - 1)\n",
        "            w -= int(weights[i - 1] * 100)\n",
        "    return selected[::-1]\n",
        "\n",
        "# ========= 3. TVSum Paths =========\n",
        "FEATURES_DIR = \"/mnt/d/Mass Projects/Video_Summ/TVSUM/RandomSplit_Dataset/resnet_npy/extracted_features_25fps_videos\"\n",
        "MAT_FILE_PATH = \"/mnt/d/Mass Projects/Video_Summ/ydata-tvsum50-v1_1/ydata-tvsum50-matlab/matlab/ydata-tvsum50.mat\"\n",
        "EXCEL_OUT = \"/mnt/d/Mass Projects/Video_Summ/RESULTS/RESULTS/TVSUM/bilstm_multi_8-heads_60k.xlsx\"\n",
        "FPS = 25\n",
        "PENALTY = 500\n",
        "CHUNK_SIZE = 500\n",
        "\n",
        "# ========= 4. Load .mat TVSum =========\n",
        "with h5py.File(MAT_FILE_PATH, \"r\") as mat_data:\n",
        "    tvsum50_group = mat_data[\"tvsum50\"]\n",
        "\n",
        "    def decode_str(ref):\n",
        "        return \"\".join(map(chr, mat_data[ref][()].flatten())).replace(\"\\x00\", \"\")\n",
        "\n",
        "    video_names = [decode_str(ref) for ref in tvsum50_group[\"video\"][:, 0]]\n",
        "    user_annos = [mat_data[ref][:] for ref in tvsum50_group[\"user_anno\"][:, 0]]\n",
        "    nframes_list = [int(mat_data[ref][()][0, 0]) for ref in tvsum50_group[\"nframes\"][:, 0]]\n",
        "\n",
        "# ========= 5. Process Videos =========\n",
        "with pd.ExcelWriter(EXCEL_OUT, engine=\"xlsxwriter\") as writer:\n",
        "    summary_data = []\n",
        "\n",
        "    for idx, video_name in enumerate(video_names):\n",
        "        print(f\"\\nüöÄ Processing video: {video_name}\")\n",
        "\n",
        "        feature_path = os.path.join(FEATURES_DIR, f\"{video_name}.npy\")\n",
        "        if not os.path.exists(feature_path):\n",
        "            print(f\"‚ùå Missing feature file: {video_name}\")\n",
        "            continue\n",
        "\n",
        "        raw_feats = np.load(feature_path)\n",
        "        num_frames = raw_feats.shape[0]\n",
        "        video_feats = raw_feats[np.newaxis, ...]\n",
        "\n",
        "        recon = np.zeros_like(video_feats)\n",
        "        for i in range((num_frames + CHUNK_SIZE - 1) // CHUNK_SIZE):\n",
        "            s, e = i * CHUNK_SIZE, min((i + 1) * CHUNK_SIZE, num_frames)\n",
        "            recon[:, s:e, :] = model.predict(video_feats[:, s:e, :], verbose=0)\n",
        "\n",
        "        errs = np.mean(np.abs(video_feats - recon), axis=2).flatten()\n",
        "        imp_scores = (errs - errs.min()) / (errs.max() - errs.min())\n",
        "\n",
        "        model_segments = detect_kts_segments(raw_feats, penalty=PENALTY)\n",
        "        segment_durations = [(end - start + 1) / FPS for start, end in model_segments]\n",
        "        segment_scores = [np.mean(imp_scores[start:end + 1]) for start, end in model_segments]\n",
        "\n",
        "        total_duration = num_frames / FPS\n",
        "        summary_duration = total_duration * 0.15\n",
        "        selected_indices = knapsack(segment_scores, segment_durations, summary_duration)\n",
        "        selected_model_segments = [model_segments[i] for i in selected_indices]\n",
        "\n",
        "        user_scores = user_annos[idx]\n",
        "        num_users = user_scores.shape[0]\n",
        "        all_user_metrics = []\n",
        "\n",
        "        for u in range(num_users):\n",
        "            user_score = user_scores[u]\n",
        "            k = int(np.floor(num_frames * 0.15))\n",
        "            selected_indices = np.argsort(user_score)[-k:]\n",
        "            user_segments = get_segments_from_indices(selected_indices.tolist())\n",
        "\n",
        "            f1, precision, recall = calculate_segment_f1(user_segments, selected_model_segments)\n",
        "            all_user_metrics.append((u + 1, f1, precision, recall))\n",
        "\n",
        "        df = pd.DataFrame(all_user_metrics, columns=[\"User\", \"F1 Score\", \"Precision\", \"Recall\"])\n",
        "        df.to_excel(writer, sheet_name=video_name[:31], index=False)\n",
        "\n",
        "        summary_data.append({\n",
        "            \"Video\": video_name,\n",
        "            \"KTS Segments\": len(model_segments),\n",
        "            \"Selected\": len(selected_model_segments),\n",
        "            \"Min F1\": df[\"F1 Score\"].min(),\n",
        "            \"Avg F1\": df[\"F1 Score\"].mean(),\n",
        "            \"Max F1\": df[\"F1 Score\"].max(),\n",
        "            \"Min Precision\": df[\"Precision\"].min(),\n",
        "            \"Avg Precision\": df[\"Precision\"].mean(),\n",
        "            \"Max Precision\": df[\"Precision\"].max(),\n",
        "            \"Min Recall\": df[\"Recall\"].min(),\n",
        "            \"Avg Recall\": df[\"Recall\"].mean(),\n",
        "            \"Max Recall\": df[\"Recall\"].max()\n",
        "        })\n",
        "\n",
        "        del video_feats, recon\n",
        "        gc.collect()\n",
        "        tf.keras.backend.clear_session()\n",
        "\n",
        "    pd.DataFrame(summary_data).to_excel(writer, sheet_name=\"Summary\", index=False)\n",
        "    print(f\"\\n‚úÖ TVSum results saved to: {EXCEL_OUT}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84b9dfde",
      "metadata": {
        "id": "84b9dfde"
      },
      "source": [
        "# NO ATTENTION TRAINING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7edc9461",
      "metadata": {
        "id": "7edc9461"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "\n",
        "# =======================\n",
        "# 1Ô∏è‚É£ GPU Memory Optimization\n",
        "# =======================\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)  # ‚úÖ Prevents full GPU memory allocation\n",
        "        print(\"‚úÖ GPU Memory Growth Enabled\")\n",
        "    except RuntimeError as e:\n",
        "        print(e)\n",
        "\n",
        "# Enable mixed precision training to reduce memory usage\n",
        "tf.keras.mixed_precision.set_global_policy(\"mixed_float16\")\n",
        "\n",
        "# =======================\n",
        "# 2Ô∏è‚É£ Load Pre-Extracted Features\n",
        "# =======================\n",
        "base_path = \"/mnt/d/Mass Projects/Video_Summ/new_dataset_features_npy_3000_1\"\n",
        "train_path = os.path.join(base_path, \"train\")\n",
        "valid_path = os.path.join(base_path, \"valid\")\n",
        "\n",
        "def load_features(directory):\n",
        "    feature_list = []\n",
        "    video_files = sorted(os.listdir(directory))  # Ensure correct order\n",
        "    for file in video_files:\n",
        "        file_path = os.path.join(directory, file)\n",
        "        features = np.load(file_path)  # Shape: (750, 2048)\n",
        "        feature_list.append(features)\n",
        "    return np.array(feature_list)  # Shape: (num_videos, seq_len, feature_dim)\n",
        "\n",
        "train_features = load_features(train_path)  # (num_train_videos, 750, 2048)\n",
        "valid_features = load_features(valid_path)  # (num_valid_videos, 750, 2048)\n",
        "\n",
        "SEQ_LEN = train_features.shape[1]  # 750\n",
        "FEATURE_DIM = train_features.shape[2]  # 2048\n",
        "NUM_EPOCHS = 50\n",
        "BATCH_SIZE = 1  # Reduce if needed to avoid OOM\n",
        "LEARNING_RATE = 1e-5\n",
        "MODEL_SAVE_PATH = \"/mnt/d/Mass Projects/Video_Summ/RESULTS/MODELS/bilstm_NO_attention_60k.keras\"\n",
        "\n",
        "os.makedirs(os.path.dirname(MODEL_SAVE_PATH), exist_ok=True)\n",
        "\n",
        "# =======================\n",
        "# 3Ô∏è‚É£ Define BiLSTM-Only Model (No Attention)\n",
        "# =======================\n",
        "class BiLSTMModel(models.Model):\n",
        "    def __init__(self, feature_dim, lstm_units=128, **kwargs):\n",
        "        super(BiLSTMModel, self).__init__(**kwargs)\n",
        "        self.feature_dim = feature_dim\n",
        "        self.lstm_units = lstm_units\n",
        "\n",
        "        # BiLSTM Layer\n",
        "        self.bilstm = layers.Bidirectional(layers.LSTM(lstm_units, return_sequences=True))\n",
        "\n",
        "        # Reconstruction Layer (to reconstruct original input)\n",
        "        self.reconstruction_layer = layers.TimeDistributed(layers.Dense(feature_dim, activation=\"linear\"))\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.bilstm(inputs)  # BiLSTM processing\n",
        "        reconstructed = self.reconstruction_layer(x)  # Reconstruct input\n",
        "        return reconstructed\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(BiLSTMModel, self).get_config()\n",
        "        config.update({\n",
        "            \"feature_dim\": self.feature_dim,\n",
        "            \"lstm_units\": self.lstm_units\n",
        "        })\n",
        "        return config\n",
        "\n",
        "    @classmethod\n",
        "    def from_config(cls, config):\n",
        "        return cls(**config)\n",
        "\n",
        "# Initialize Model\n",
        "model = BiLSTMModel(feature_dim=FEATURE_DIM)\n",
        "\n",
        "# Explicitly Build Model Before Saving\n",
        "model.build(input_shape=(None, SEQ_LEN, FEATURE_DIM))\n",
        "\n",
        "# Compile Model\n",
        "model.compile(optimizer=optimizers.Adam(learning_rate=LEARNING_RATE),\n",
        "              loss=\"mse\",  # Mean Squared Error for reconstruction loss\n",
        "              metrics=[\"mae\"])\n",
        "\n",
        "# =======================\n",
        "# 4Ô∏è‚É£ Train Model (Unsupervised)\n",
        "# =======================\n",
        "print(\"üöÄ Starting Training...\")\n",
        "history = model.fit(train_features, train_features,  # Unsupervised: reconstruct input\n",
        "                    validation_data=(valid_features, valid_features),\n",
        "                    epochs=NUM_EPOCHS, batch_size=BATCH_SIZE)\n",
        "\n",
        "# Save Model\n",
        "model.save(MODEL_SAVE_PATH)\n",
        "print(f\"‚úÖ Model saved at {MODEL_SAVE_PATH}\")\n",
        "\n",
        "# =======================\n",
        "# 5Ô∏è‚É£ Evaluation (Inference)\n",
        "# =======================\n",
        "with tf.keras.utils.custom_object_scope({\"BiLSTMModel\": BiLSTMModel}):\n",
        "    model = tf.keras.models.load_model(MODEL_SAVE_PATH)\n",
        "\n",
        "print(\"üîÑ Model loaded for evaluation.\")\n",
        "\n",
        "# Example evaluation on a validation video\n",
        "test_video = valid_features[0:1]  # Shape: (1, 750, 2048)\n",
        "reconstructed_video = model.predict(test_video)\n",
        "print(\"Reconstructed Features Shape:\", reconstructed_video.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ea5d529",
      "metadata": {
        "id": "9ea5d529"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "\n",
        "# =======================\n",
        "# 1Ô∏è‚É£ GPU Memory Optimization\n",
        "# =======================\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        print(\"‚úÖ GPU Memory Growth Enabled\")\n",
        "    except RuntimeError as e:\n",
        "        print(e)\n",
        "\n",
        "# Enable mixed precision\n",
        "tf.keras.mixed_precision.set_global_policy(\"mixed_float16\")\n",
        "\n",
        "# =======================\n",
        "# 2Ô∏è‚É£ Load Features with Sliding Windows\n",
        "# =======================\n",
        "base_path = \"/mnt/d/Mass Projects/Video_Summ/new_dataset_features_npy_1750\"\n",
        "train_path = os.path.join(base_path, \"train\")\n",
        "valid_path = os.path.join(base_path, \"valid\")\n",
        "\n",
        "SEQ_LEN = 150\n",
        "STRIDE = 125\n",
        "FEATURE_DIM = 2048\n",
        "\n",
        "def load_features(directory):\n",
        "    all_windows = []\n",
        "    video_files = sorted(os.listdir(directory))\n",
        "    for file in video_files:\n",
        "        file_path = os.path.join(directory, file)\n",
        "        features = np.load(file_path)  # shape: (1750, 2048)\n",
        "        for start in range(0, len(features) - SEQ_LEN + 1, STRIDE):\n",
        "            window = features[start:start+SEQ_LEN]\n",
        "            all_windows.append(window)\n",
        "    return np.array(all_windows, dtype=np.float32)\n",
        "\n",
        "print(\"üì• Loading dataset...\")\n",
        "train_features = load_features(train_path)\n",
        "valid_features = load_features(valid_path)\n",
        "print(\"Train windows:\", train_features.shape)\n",
        "print(\"Valid windows:\", valid_features.shape)\n",
        "\n",
        "NUM_EPOCHS = 50\n",
        "BATCH_SIZE = 1\n",
        "LEARNING_RATE = 1e-5\n",
        "MODEL_SAVE_PATH = \"/mnt/d/Mass Projects/Video_Summ/RESULTS/Models_2/SUMME/bilstm_no_attention_35k.keras\"\n",
        "os.makedirs(os.path.dirname(MODEL_SAVE_PATH), exist_ok=True)\n",
        "\n",
        "# =======================\n",
        "# 3Ô∏è‚É£ Define BiLSTM Autoencoder (No Attention)\n",
        "# =======================\n",
        "class BiLSTMNoAttentionModel(models.Model):\n",
        "    def __init__(self, feature_dim, lstm_units=64, **kwargs):\n",
        "        super(BiLSTMNoAttentionModel, self).__init__(**kwargs)\n",
        "        self.feature_dim = feature_dim\n",
        "        self.lstm_units = lstm_units\n",
        "\n",
        "        self.bilstm = layers.Bidirectional(\n",
        "            layers.LSTM(lstm_units, return_sequences=True)\n",
        "        )\n",
        "        self.reconstruction_layer = layers.TimeDistributed(\n",
        "            layers.Dense(feature_dim, activation=\"linear\")\n",
        "        )\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.bilstm(inputs)\n",
        "        reconstructed = self.reconstruction_layer(x)\n",
        "        return reconstructed\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(BiLSTMNoAttentionModel, self).get_config()\n",
        "        config.update({\n",
        "            \"feature_dim\": self.feature_dim,\n",
        "            \"lstm_units\": self.lstm_units\n",
        "        })\n",
        "        return config\n",
        "\n",
        "    @classmethod\n",
        "    def from_config(cls, config):\n",
        "        return cls(**config)\n",
        "\n",
        "# =======================\n",
        "# 4Ô∏è‚É£ Build + Compile Model\n",
        "# =======================\n",
        "model = BiLSTMNoAttentionModel(feature_dim=FEATURE_DIM)\n",
        "model.build(input_shape=(None, SEQ_LEN, FEATURE_DIM))\n",
        "\n",
        "model.compile(\n",
        "    optimizer=optimizers.Adam(learning_rate=LEARNING_RATE),\n",
        "    loss=\"mse\",\n",
        "    metrics=[\"mae\"]\n",
        ")\n",
        "\n",
        "# =======================\n",
        "# 5Ô∏è‚É£ Training\n",
        "# =======================\n",
        "print(\"üöÄ Starting Training (No Attention)...\")\n",
        "history = model.fit(\n",
        "    train_features, train_features,\n",
        "    validation_data=(valid_features, valid_features),\n",
        "    epochs=NUM_EPOCHS,\n",
        "    batch_size=BATCH_SIZE\n",
        ")\n",
        "\n",
        "model.save(MODEL_SAVE_PATH)\n",
        "print(f\"‚úÖ Model saved at {MODEL_SAVE_PATH}\")\n",
        "\n",
        "# =======================\n",
        "# 6Ô∏è‚É£ Evaluation\n",
        "# =======================\n",
        "with tf.keras.utils.custom_object_scope({\"BiLSTMNoAttentionModel\": BiLSTMNoAttentionModel}):\n",
        "    model = tf.keras.models.load_model(MODEL_SAVE_PATH)\n",
        "\n",
        "print(\"üîÑ Model loaded for evaluation.\")\n",
        "\n",
        "test_video = valid_features[0:1]  # (1, SEQ_LEN, 2048)\n",
        "reconstructed_video = model.predict(test_video)\n",
        "print(\"Reconstructed Features Shape:\", reconstructed_video.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "03f95636",
      "metadata": {
        "id": "03f95636"
      },
      "source": [
        "# NO Attention - SUMME"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "773cbcd5",
      "metadata": {
        "id": "773cbcd5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import scipy.io\n",
        "import ruptures as rpt\n",
        "import pandas as pd\n",
        "import gc\n",
        "\n",
        "# ========= 1Ô∏è‚É£ Load No-Attention BiLSTM Model =========\n",
        "class BiLSTMNoAttentionModel(tf.keras.Model):\n",
        "    def __init__(self, feature_dim=2048, lstm_units=64, **kwargs):\n",
        "        super(BiLSTMNoAttentionModel, self).__init__(**kwargs)\n",
        "        self.bilstm = tf.keras.layers.Bidirectional(\n",
        "            tf.keras.layers.LSTM(lstm_units, return_sequences=True)\n",
        "        )\n",
        "        self.reconstruction_layer = tf.keras.layers.TimeDistributed(\n",
        "            tf.keras.layers.Dense(feature_dim, activation=\"linear\")\n",
        "        )\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.bilstm(inputs)\n",
        "        return self.reconstruction_layer(x)\n",
        "\n",
        "MODEL_PATH = \"/mnt/d/Mass Projects/Video_Summ/RESULTS/Models_2/SUMME/bilstm_no_attention_35k.keras\"\n",
        "\n",
        "with tf.keras.utils.custom_object_scope({\"BiLSTMNoAttentionModel\": BiLSTMNoAttentionModel}):\n",
        "    model = tf.keras.models.load_model(MODEL_PATH)\n",
        "\n",
        "print(\"\\n‚úÖ BiLSTM No-Attention model loaded successfully\")\n",
        "\n",
        "# ========= 2Ô∏è‚É£ Helper Functions =========\n",
        "def get_segments_from_indices(indices):\n",
        "    if not indices:\n",
        "        return []\n",
        "    indices = sorted(set(indices))\n",
        "    segments, start = [], indices[0]\n",
        "    for i in range(1, len(indices)):\n",
        "        if indices[i] != indices[i - 1] + 1:\n",
        "            segments.append((start, indices[i - 1]))\n",
        "            start = indices[i]\n",
        "    segments.append((start, indices[-1]))\n",
        "    return segments\n",
        "\n",
        "def expand_segment(seg):\n",
        "    return list(range(seg[0], seg[1] + 1))\n",
        "\n",
        "def calculate_segment_f1(user_segments, model_segments):\n",
        "    tp = 0\n",
        "    for m_seg in model_segments:\n",
        "        m_range = set(expand_segment(m_seg))\n",
        "        for u_seg in user_segments:\n",
        "            u_range = set(expand_segment(u_seg))\n",
        "            if m_range & u_range:\n",
        "                tp += 1\n",
        "                break\n",
        "    precision = tp / len(model_segments) if model_segments else 0\n",
        "    recall = tp / len(user_segments) if user_segments else 0\n",
        "    f1 = 2 * precision * recall / (precision + recall) if precision + recall else 0\n",
        "    return f1, precision, recall\n",
        "\n",
        "def detect_kts_segments(features, penalty=500):\n",
        "    algo = rpt.KernelCPD(kernel=\"linear\").fit(features)\n",
        "    change_points = algo.predict(pen=penalty)\n",
        "    change_points = [int(cp) for cp in change_points]\n",
        "    segments = []\n",
        "    start = 0\n",
        "    for cp in change_points:\n",
        "        segments.append((start, cp - 1))\n",
        "        start = cp\n",
        "    if segments[-1][1] < features.shape[0] - 1:\n",
        "        segments.append((start, features.shape[0] - 1))\n",
        "    return segments\n",
        "\n",
        "def knapsack(values, weights, capacity):\n",
        "    n = len(values)\n",
        "    dp = [[0 for _ in range(int(capacity * 100) + 1)] for _ in range(n + 1)]\n",
        "    for i in range(1, n + 1):\n",
        "        for w in range(int(capacity * 100) + 1):\n",
        "            weight = int(weights[i - 1] * 100)\n",
        "            if weight <= w:\n",
        "                dp[i][w] = max(values[i - 1] + dp[i - 1][w - weight], dp[i - 1][w])\n",
        "            else:\n",
        "                dp[i][w] = dp[i - 1][w]\n",
        "    selected = []\n",
        "    w = int(capacity * 100)\n",
        "    for i in range(n, 0, -1):\n",
        "        if dp[i][w] != dp[i - 1][w]:\n",
        "            selected.append(i - 1)\n",
        "            w -= int(weights[i - 1] * 100)\n",
        "    return selected[::-1]\n",
        "\n",
        "# ========= 3Ô∏è‚É£ Process Videos =========\n",
        "video_list = [\n",
        "    \"Jumps\", \"Base Jumping\", \"Air_Force_One\", \"Bearpark_climbing\", \"Bike Polo\",\n",
        "    \"Bus_in_Rock_Tunnel\", \"car_over_camera\", \"Car_railcrossing\", \"Cockpit_Landing\", \"Cooking\",\n",
        "    \"Eiffel Tower\", \"Excavators river crossing\", \"Fire Domino\", \"Kids_playing_in_leaves\",\n",
        "    \"Notre_Dame\", \"Paintball\", \"paluma_jump\", \"playing_ball\", \"Playing_on_water_slide\",\n",
        "    \"Saving dolphines\", \"Scuba\", \"St Maarten Landing\", \"Statue of Liberty\", \"Valparaiso_Downhill\"\n",
        "]\n",
        "\n",
        "FEATURES_DIR = \"/mnt/d/Mass Projects/Video_Summ/extracted_features/\"\n",
        "MAT_DIR = \"/mnt/d/Mass Projects/Video_Summ/mat/\"\n",
        "CHUNK_SIZE = 500\n",
        "PENALTY = 500\n",
        "FPS = 25\n",
        "SUMMARY_EXCEL = \"/mnt/d/Mass Projects/Video_Summ/RESULTS/Results_2/SUMME/bilstm_no_attention_35k.xlsx\"\n",
        "\n",
        "with pd.ExcelWriter(SUMMARY_EXCEL, engine=\"xlsxwriter\") as writer:\n",
        "    summary_data = []\n",
        "\n",
        "    for VIDEO_NAME in video_list:\n",
        "        print(f\"\\n==============================\\nüöÄ Processing video: {VIDEO_NAME}\\n==============================\")\n",
        "\n",
        "        feats_path = os.path.join(FEATURES_DIR, f\"{VIDEO_NAME}.npy\")\n",
        "        mat_path = os.path.join(MAT_DIR, f\"{VIDEO_NAME}.mat\")\n",
        "        if not os.path.exists(feats_path) or not os.path.exists(mat_path):\n",
        "            print(\"‚ùå Skipping, missing file.\")\n",
        "            continue\n",
        "\n",
        "        raw_feats = np.load(feats_path)\n",
        "        num_frames = raw_feats.shape[0]\n",
        "        video_feats = raw_feats[np.newaxis, ...]\n",
        "\n",
        "        # Reconstruction in chunks\n",
        "        recon = np.zeros_like(video_feats)\n",
        "        for i in range((num_frames + CHUNK_SIZE - 1) // CHUNK_SIZE):\n",
        "            s, e = i * CHUNK_SIZE, min((i + 1) * CHUNK_SIZE, num_frames)\n",
        "            recon[:, s:e, :] = model.predict(video_feats[:, s:e, :], verbose=0)\n",
        "        print(\"‚úÖ Features reconstructed\")\n",
        "\n",
        "        # Compute importance scores (based on reconstruction error)\n",
        "        errs = np.mean(np.abs(video_feats - recon), axis=2).flatten()\n",
        "        imp_scores = (errs - errs.min()) / (errs.max() - errs.min())\n",
        "\n",
        "        # Segment detection using KTS\n",
        "        model_segments = detect_kts_segments(raw_feats, penalty=PENALTY)\n",
        "        segment_durations = [(end - start + 1) / FPS for start, end in model_segments]\n",
        "        segment_scores = [np.mean(imp_scores[start:end + 1]) for start, end in model_segments]\n",
        "\n",
        "        # Knapsack summary selection (15% of total duration)\n",
        "        total_duration = num_frames / FPS\n",
        "        summary_duration = total_duration * 0.15\n",
        "        selected_indices = knapsack(segment_scores, segment_durations, summary_duration)\n",
        "        selected_model_segments = [model_segments[i] for i in selected_indices]\n",
        "\n",
        "        # Load ground-truth user summaries\n",
        "        mat = scipy.io.loadmat(mat_path)\n",
        "        user_scores = mat['user_score']\n",
        "        num_users = user_scores.shape[1]\n",
        "        all_user_metrics = []\n",
        "\n",
        "        for u in range(num_users):\n",
        "            usr = user_scores[:, u]\n",
        "            nonzero_indices = np.where(usr > 0)[0]\n",
        "            user_segments = get_segments_from_indices(nonzero_indices.tolist())\n",
        "\n",
        "            f1, precision, recall = calculate_segment_f1(user_segments, selected_model_segments)\n",
        "            all_user_metrics.append((u + 1, f1, precision, recall))\n",
        "\n",
        "        df = pd.DataFrame(all_user_metrics, columns=[\"User\", \"F1 Score\", \"Precision\", \"Recall\"])\n",
        "        df.to_excel(writer, sheet_name=VIDEO_NAME[:31], index=False)\n",
        "\n",
        "        summary_data.append({\n",
        "            \"Video Name\": VIDEO_NAME,\n",
        "            \"KTS Segments\": len(model_segments),\n",
        "            \"Knapsack Selected\": len(selected_model_segments),\n",
        "            \"Penalty\": PENALTY,\n",
        "            \"Min Precision\": df[\"Precision\"].min(),\n",
        "            \"Avg Precision\": df[\"Precision\"].mean(),\n",
        "            \"Max Precision\": df[\"Precision\"].max(),\n",
        "            \"Min Recall\": df[\"Recall\"].min(),\n",
        "            \"Avg Recall\": df[\"Recall\"].mean(),\n",
        "            \"Max Recall\": df[\"Recall\"].max(),\n",
        "            \"Min F1\": df[\"F1 Score\"].min(),\n",
        "            \"Avg F1\": df[\"F1 Score\"].mean(),\n",
        "            \"Max F1\": df[\"F1 Score\"].max(),\n",
        "        })\n",
        "\n",
        "        del video_feats, recon\n",
        "        gc.collect()\n",
        "        tf.keras.backend.clear_session()\n",
        "\n",
        "    # Save summary sheet\n",
        "    pd.DataFrame(summary_data).to_excel(writer, sheet_name=\"Summary\", index=False)\n",
        "    print(f\"\\n‚úÖ All results saved to: {SUMMARY_EXCEL}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "44f34657",
      "metadata": {
        "id": "44f34657"
      },
      "source": [
        "# NO Attention TVSUM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b079e47",
      "metadata": {
        "id": "4b079e47"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import h5py\n",
        "import gc\n",
        "import ruptures as rpt\n",
        "\n",
        "# ========= 1. Load Model (BiLSTM without Attention) =========\n",
        "class BiLSTMNoAttentionModel(tf.keras.Model):\n",
        "    def __init__(self, feature_dim=2048, lstm_units=128, **kwargs):\n",
        "        super(BiLSTMNoAttentionModel, self).__init__(**kwargs)\n",
        "        self.bilstm = tf.keras.layers.Bidirectional(\n",
        "            tf.keras.layers.LSTM(lstm_units, return_sequences=True)\n",
        "        )\n",
        "        self.reconstruction_layer = tf.keras.layers.TimeDistributed(\n",
        "            tf.keras.layers.Dense(feature_dim, activation=\"linear\")\n",
        "        )\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.bilstm(inputs)\n",
        "        return self.reconstruction_layer(x)\n",
        "\n",
        "MODEL_PATH = \"/mnt/d/Mass Projects/Video_Summ/RESULTS/MODELS/bilstm_no_attention_15k.keras\"\n",
        "with tf.keras.utils.custom_object_scope({\"BiLSTMNoAttentionModel\": BiLSTMNoAttentionModel}):\n",
        "    model = tf.keras.models.load_model(MODEL_PATH)\n",
        "\n",
        "print(\"\\n‚úÖ No-attention BiLSTM model loaded successfully\")\n",
        "\n",
        "# ========= 2. Helper Functions =========\n",
        "def get_segments_from_indices(indices):\n",
        "    if not indices:\n",
        "        return []\n",
        "    indices = sorted(set(indices))\n",
        "    segments, start = [], indices[0]\n",
        "    for i in range(1, len(indices)):\n",
        "        if indices[i] != indices[i - 1] + 1:\n",
        "            segments.append((start, indices[i - 1]))\n",
        "            start = indices[i]\n",
        "    segments.append((start, indices[-1]))\n",
        "    return segments\n",
        "\n",
        "def expand_segment(seg):\n",
        "    return list(range(seg[0], seg[1] + 1))\n",
        "\n",
        "def calculate_segment_f1(user_segments, model_segments):\n",
        "    tp = 0\n",
        "    for m_seg in model_segments:\n",
        "        m_range = set(expand_segment(m_seg))\n",
        "        for u_seg in user_segments:\n",
        "            u_range = set(expand_segment(u_seg))\n",
        "            if m_range & u_range:\n",
        "                tp += 1\n",
        "                break\n",
        "    precision = tp / len(model_segments) if model_segments else 0\n",
        "    recall = tp / len(user_segments) if user_segments else 0\n",
        "    f1 = 2 * precision * recall / (precision + recall) if precision + recall else 0\n",
        "    return f1, precision, recall\n",
        "\n",
        "def detect_kts_segments(features, penalty=500):\n",
        "    algo = rpt.KernelCPD(kernel=\"linear\").fit(features)\n",
        "    change_points = algo.predict(pen=penalty)\n",
        "    change_points = [int(cp) for cp in change_points]\n",
        "    scene_segments = []\n",
        "    start_frame = 0\n",
        "    for cp in change_points:\n",
        "        scene_segments.append((start_frame, cp - 1))\n",
        "        start_frame = cp\n",
        "    if scene_segments[-1][1] < features.shape[0] - 1:\n",
        "        scene_segments.append((start_frame, features.shape[0] - 1))\n",
        "    return scene_segments\n",
        "\n",
        "def knapsack(values, weights, capacity):\n",
        "    n = len(values)\n",
        "    dp = [[0 for _ in range(int(capacity * 100) + 1)] for _ in range(n + 1)]\n",
        "    for i in range(1, n + 1):\n",
        "        for w in range(int(capacity * 100) + 1):\n",
        "            weight = int(weights[i - 1] * 100)\n",
        "            if weight <= w:\n",
        "                dp[i][w] = max(values[i - 1] + dp[i - 1][w - weight], dp[i - 1][w])\n",
        "            else:\n",
        "                dp[i][w] = dp[i - 1][w]\n",
        "    selected = []\n",
        "    w = int(capacity * 100)\n",
        "    for i in range(n, 0, -1):\n",
        "        if dp[i][w] != dp[i - 1][w]:\n",
        "            selected.append(i - 1)\n",
        "            w -= int(weights[i - 1] * 100)\n",
        "    return selected[::-1]\n",
        "\n",
        "# ========= 3. TVSum Paths =========\n",
        "FEATURES_DIR = \"/mnt/d/Mass Projects/Video_Summ/TVSUM/RandomSplit_Dataset/resnet_npy/extracted_features_25fps_videos\"\n",
        "MAT_FILE_PATH = \"/mnt/d/Mass Projects/Video_Summ/ydata-tvsum50-v1_1/ydata-tvsum50-matlab/matlab/ydata-tvsum50.mat\"\n",
        "EXCEL_OUT = \"/mnt/d/Mass Projects/Video_Summ/RESULTS/RESULTS/TVSUM/bilstm_no_attention_15k.xlsx\"\n",
        "FPS = 25\n",
        "PENALTY = 500\n",
        "CHUNK_SIZE = 500\n",
        "\n",
        "# ========= 4. Load .mat TVSum =========\n",
        "with h5py.File(MAT_FILE_PATH, \"r\") as mat_data:\n",
        "    tvsum50_group = mat_data[\"tvsum50\"]\n",
        "\n",
        "    def decode_str(ref):\n",
        "        return \"\".join(map(chr, mat_data[ref][()].flatten())).replace(\"\\x00\", \"\")\n",
        "\n",
        "    video_names = [decode_str(ref) for ref in tvsum50_group[\"video\"][:, 0]]\n",
        "    user_annos = [mat_data[ref][:] for ref in tvsum50_group[\"user_anno\"][:, 0]]\n",
        "    nframes_list = [int(mat_data[ref][()][0, 0]) for ref in tvsum50_group[\"nframes\"][:, 0]]\n",
        "\n",
        "# ========= 5. Process Videos =========\n",
        "with pd.ExcelWriter(EXCEL_OUT, engine=\"xlsxwriter\") as writer:\n",
        "    summary_data = []\n",
        "\n",
        "    for idx, video_name in enumerate(video_names):\n",
        "        print(f\"\\nüöÄ Processing video: {video_name}\")\n",
        "\n",
        "        feature_path = os.path.join(FEATURES_DIR, f\"{video_name}.npy\")\n",
        "        if not os.path.exists(feature_path):\n",
        "            print(f\"‚ùå Missing feature file: {video_name}\")\n",
        "            continue\n",
        "\n",
        "        raw_feats = np.load(feature_path)\n",
        "        num_frames = raw_feats.shape[0]\n",
        "        video_feats = raw_feats[np.newaxis, ...]\n",
        "\n",
        "        recon = np.zeros_like(video_feats)\n",
        "        for i in range((num_frames + CHUNK_SIZE - 1) // CHUNK_SIZE):\n",
        "            s, e = i * CHUNK_SIZE, min((i + 1) * CHUNK_SIZE, num_frames)\n",
        "            recon[:, s:e, :] = model.predict(video_feats[:, s:e, :], verbose=0)\n",
        "\n",
        "        errs = np.mean(np.abs(video_feats - recon), axis=2).flatten()\n",
        "        imp_scores = (errs - errs.min()) / (errs.max() - errs.min())\n",
        "\n",
        "        model_segments = detect_kts_segments(raw_feats, penalty=PENALTY)\n",
        "        segment_durations = [(end - start + 1) / FPS for start, end in model_segments]\n",
        "        segment_scores = [np.mean(imp_scores[start:end + 1]) for start, end in model_segments]\n",
        "\n",
        "        total_duration = num_frames / FPS\n",
        "        summary_duration = total_duration * 0.15\n",
        "        selected_indices = knapsack(segment_scores, segment_durations, summary_duration)\n",
        "        selected_model_segments = [model_segments[i] for i in selected_indices]\n",
        "\n",
        "        user_scores = user_annos[idx]\n",
        "        num_users = user_scores.shape[0]\n",
        "        all_user_metrics = []\n",
        "\n",
        "        for u in range(num_users):\n",
        "            user_score = user_scores[u]\n",
        "            k = int(np.floor(num_frames * 0.15))\n",
        "            selected_indices = np.argsort(user_score)[-k:]\n",
        "            user_segments = get_segments_from_indices(selected_indices.tolist())\n",
        "\n",
        "            f1, precision, recall = calculate_segment_f1(user_segments, selected_model_segments)\n",
        "            all_user_metrics.append((u + 1, f1, precision, recall))\n",
        "\n",
        "        df = pd.DataFrame(all_user_metrics, columns=[\"User\", \"F1 Score\", \"Precision\", \"Recall\"])\n",
        "        df.to_excel(writer, sheet_name=video_name[:31], index=False)\n",
        "\n",
        "        summary_data.append({\n",
        "            \"Video\": video_name,\n",
        "            \"KTS Segments\": len(model_segments),\n",
        "            \"Selected\": len(selected_model_segments),\n",
        "            \"Min F1\": df[\"F1 Score\"].min(),\n",
        "            \"Avg F1\": df[\"F1 Score\"].mean(),\n",
        "            \"Max F1\": df[\"F1 Score\"].max(),\n",
        "            \"Min Precision\": df[\"Precision\"].min(),\n",
        "            \"Avg Precision\": df[\"Precision\"].mean(),\n",
        "            \"Max Precision\": df[\"Precision\"].max(),\n",
        "            \"Min Recall\": df[\"Recall\"].min(),\n",
        "            \"Avg Recall\": df[\"Recall\"].mean(),\n",
        "            \"Max Recall\": df[\"Recall\"].max()\n",
        "        })\n",
        "\n",
        "        del video_feats, recon\n",
        "        gc.collect()\n",
        "        tf.keras.backend.clear_session()\n",
        "\n",
        "    pd.DataFrame(summary_data).to_excel(writer, sheet_name=\"Summary\", index=False)\n",
        "    print(f\"\\n‚úÖ TVSum results saved to: {EXCEL_OUT}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6cf2dca0",
      "metadata": {
        "id": "6cf2dca0"
      },
      "source": [
        "# BILSTM - SOFT ATTENTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6b9df6d",
      "metadata": {
        "id": "b6b9df6d"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, optimizers, backend as K\n",
        "\n",
        "# =======================\n",
        "# 1Ô∏è‚É£ GPU Memory Optimization\n",
        "# =======================\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        print(\"‚úÖ GPU Memory Growth Enabled\")\n",
        "    except RuntimeError as e:\n",
        "        print(e)\n",
        "\n",
        "# Enable mixed precision\n",
        "tf.keras.mixed_precision.set_global_policy(\"mixed_float16\")\n",
        "\n",
        "# =======================\n",
        "# 2Ô∏è‚É£ Load Features with Sliding Windows\n",
        "# =======================\n",
        "base_path = \"/mnt/d/Mass Projects/Video_Summ/new_dataset_features_npy_1750\"\n",
        "train_path = os.path.join(base_path, \"train\")\n",
        "valid_path = os.path.join(base_path, \"valid\")\n",
        "\n",
        "SEQ_LEN = 150\n",
        "STRIDE = 125\n",
        "FEATURE_DIM = 2048\n",
        "\n",
        "def load_features(directory):\n",
        "    all_windows = []\n",
        "    video_files = sorted(os.listdir(directory))\n",
        "    for file in video_files:\n",
        "        file_path = os.path.join(directory, file)\n",
        "        features = np.load(file_path)\n",
        "        for start in range(0, len(features) - SEQ_LEN + 1, STRIDE):\n",
        "            window = features[start:start + SEQ_LEN]\n",
        "            all_windows.append(window)\n",
        "    return np.array(all_windows, dtype=np.float32)\n",
        "\n",
        "print(\"üì• Loading dataset...\")\n",
        "train_features = load_features(train_path)\n",
        "valid_features = load_features(valid_path)\n",
        "print(\"Train windows:\", train_features.shape)\n",
        "print(\"Valid windows:\", valid_features.shape)\n",
        "\n",
        "NUM_EPOCHS = 50\n",
        "BATCH_SIZE = 1\n",
        "LEARNING_RATE = 1e-5\n",
        "MODEL_SAVE_PATH = \"/mnt/d/Mass Projects/Video_Summ/RESULTS/Models_2/SUMME/bilstm_soft_attention_15k.keras\"\n",
        "os.makedirs(os.path.dirname(MODEL_SAVE_PATH), exist_ok=True)\n",
        "\n",
        "# =======================\n",
        "# 3Ô∏è‚É£ Define Soft Attention Layer\n",
        "# =======================\n",
        "class SoftAttention(layers.Layer):\n",
        "    def __init__(self):\n",
        "        super(SoftAttention, self).__init__()\n",
        "        self.W = layers.Dense(1, activation='tanh')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # inputs: (batch, time, features)\n",
        "        score = self.W(inputs)  # (batch, time, 1)\n",
        "        attention_weights = tf.nn.softmax(score, axis=1)  # normalize over time\n",
        "        context = attention_weights * inputs  # (batch, time, features)\n",
        "        context = tf.reduce_sum(context, axis=1, keepdims=True)  # (batch, 1, features)\n",
        "        # Repeat context to match sequence length\n",
        "        context_repeated = tf.tile(context, [1, tf.shape(inputs)[1], 1])\n",
        "        return context_repeated\n",
        "\n",
        "# =======================\n",
        "# 4Ô∏è‚É£ Define BiLSTM + Soft Attention Model\n",
        "# =======================\n",
        "class BiLSTMSoftAttentionModel(models.Model):\n",
        "    def __init__(self, feature_dim=2048, lstm_units=64, **kwargs):\n",
        "        super(BiLSTMSoftAttentionModel, self).__init__(**kwargs)\n",
        "        self.bilstm = layers.Bidirectional(\n",
        "            layers.LSTM(lstm_units, return_sequences=True)\n",
        "        )\n",
        "        self.attention = SoftAttention()\n",
        "        self.reconstruction_layer = layers.TimeDistributed(\n",
        "            layers.Dense(feature_dim, activation=\"linear\")\n",
        "        )\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.bilstm(inputs)\n",
        "        context = self.attention(x)\n",
        "        x = x + context  # add context as residual\n",
        "        reconstructed = self.reconstruction_layer(x)\n",
        "        return reconstructed\n",
        "\n",
        "# =======================\n",
        "# 5Ô∏è‚É£ Build + Compile Model\n",
        "# =======================\n",
        "model = BiLSTMSoftAttentionModel(feature_dim=FEATURE_DIM)\n",
        "model.build(input_shape=(None, SEQ_LEN, FEATURE_DIM))\n",
        "\n",
        "model.compile(\n",
        "    optimizer=optimizers.Adam(learning_rate=LEARNING_RATE),\n",
        "    loss=\"mse\",\n",
        "    metrics=[\"mae\"]\n",
        ")\n",
        "\n",
        "# =======================\n",
        "# 6Ô∏è‚É£ Training\n",
        "# =======================\n",
        "print(\"üöÄ Starting Training...\")\n",
        "history = model.fit(\n",
        "    train_features, train_features,\n",
        "    validation_data=(valid_features, valid_features),\n",
        "    epochs=NUM_EPOCHS,\n",
        "    batch_size=BATCH_SIZE\n",
        ")\n",
        "\n",
        "model.save(MODEL_SAVE_PATH)\n",
        "print(f\"‚úÖ Model saved at {MODEL_SAVE_PATH}\")\n",
        "\n",
        "# =======================\n",
        "# 7Ô∏è‚É£ Evaluation\n",
        "# =======================\n",
        "with tf.keras.utils.custom_object_scope({\n",
        "    \"BiLSTMSoftAttentionModel\": BiLSTMSoftAttentionModel,\n",
        "    \"SoftAttention\": SoftAttention\n",
        "}):\n",
        "    model = tf.keras.models.load_model(MODEL_SAVE_PATH)\n",
        "\n",
        "print(\"üîÑ Model loaded for evaluation.\")\n",
        "\n",
        "test_video = valid_features[0:1]\n",
        "reconstructed_video = model.predict(test_video)\n",
        "print(\"Reconstructed Features Shape:\", reconstructed_video.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1a1531b",
      "metadata": {
        "id": "b1a1531b"
      },
      "source": [
        "# SOFT Attention - SUMME"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0385592",
      "metadata": {
        "id": "b0385592"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import scipy.io\n",
        "import ruptures as rpt\n",
        "import pandas as pd\n",
        "import gc\n",
        "\n",
        "# ========= 1Ô∏è‚É£ Define Soft Attention Model (same as training) =========\n",
        "class SoftAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self):\n",
        "        super(SoftAttention, self).__init__()\n",
        "        self.W = tf.keras.layers.Dense(1, activation='tanh')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        score = self.W(inputs)  # (batch, time, 1)\n",
        "        attention_weights = tf.nn.softmax(score, axis=1)\n",
        "        context = attention_weights * inputs\n",
        "        context = tf.reduce_sum(context, axis=1, keepdims=True)\n",
        "        context_repeated = tf.tile(context, [1, tf.shape(inputs)[1], 1])\n",
        "        return context_repeated\n",
        "\n",
        "class BiLSTMSoftAttentionModel(tf.keras.Model):\n",
        "    def __init__(self, feature_dim=2048, lstm_units=64, **kwargs):\n",
        "        super(BiLSTMSoftAttentionModel, self).__init__(**kwargs)\n",
        "        self.bilstm = tf.keras.layers.Bidirectional(\n",
        "            tf.keras.layers.LSTM(lstm_units, return_sequences=True)\n",
        "        )\n",
        "        self.attention = SoftAttention()\n",
        "        self.reconstruction_layer = tf.keras.layers.TimeDistributed(\n",
        "            tf.keras.layers.Dense(feature_dim, activation=\"linear\")\n",
        "        )\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.bilstm(inputs)\n",
        "        context = self.attention(x)\n",
        "        x = x + context  # residual connection\n",
        "        reconstructed = self.reconstruction_layer(x)\n",
        "        return reconstructed\n",
        "\n",
        "# ========= 2Ô∏è‚É£ Load Trained Model =========\n",
        "MODEL_PATH = \"/mnt/d/Mass Projects/Video_Summ/RESULTS/Models_2/SUMME/bilstm_VAE_60k.keras\"\n",
        "with tf.keras.utils.custom_object_scope({\n",
        "    \"BiLSTMSoftAttentionModel\": BiLSTMSoftAttentionModel,\n",
        "    \"SoftAttention\": SoftAttention\n",
        "}):\n",
        "    model = tf.keras.models.load_model(MODEL_PATH)\n",
        "\n",
        "print(\"\\n‚úÖ Soft Attention Model loaded successfully\")\n",
        "\n",
        "# ========= 3Ô∏è‚É£ Helper Functions =========\n",
        "def get_segments_from_indices(indices):\n",
        "    if not indices:\n",
        "        return []\n",
        "    indices = sorted(set(indices))\n",
        "    segments, start = [], indices[0]\n",
        "    for i in range(1, len(indices)):\n",
        "        if indices[i] != indices[i - 1] + 1:\n",
        "            segments.append((start, indices[i - 1]))\n",
        "            start = indices[i]\n",
        "    segments.append((start, indices[-1]))\n",
        "    return segments\n",
        "\n",
        "def expand_segment(seg):\n",
        "    return list(range(seg[0], seg[1] + 1))\n",
        "\n",
        "def calculate_segment_f1(user_segments, model_segments):\n",
        "    tp = 0\n",
        "    for m_seg in model_segments:\n",
        "        m_range = set(expand_segment(m_seg))\n",
        "        for u_seg in user_segments:\n",
        "            u_range = set(expand_segment(u_seg))\n",
        "            if m_range & u_range:\n",
        "                tp += 1\n",
        "                break\n",
        "    precision = tp / len(model_segments) if model_segments else 0\n",
        "    recall = tp / len(user_segments) if user_segments else 0\n",
        "    f1 = 2 * precision * recall / (precision + recall) if precision + recall else 0\n",
        "    return f1, precision, recall\n",
        "\n",
        "def detect_kts_segments(features, penalty=500):\n",
        "    algo = rpt.KernelCPD(kernel=\"linear\").fit(features)\n",
        "    cps = algo.predict(pen=penalty)\n",
        "    segments, start = [], 0\n",
        "    for cp in cps:\n",
        "        segments.append((start, cp - 1))\n",
        "        start = cp\n",
        "    if segments[-1][1] < features.shape[0] - 1:\n",
        "        segments.append((start, features.shape[0] - 1))\n",
        "    return segments\n",
        "\n",
        "def knapsack(values, weights, capacity):\n",
        "    n = len(values)\n",
        "    dp = [[0 for _ in range(int(capacity * 100) + 1)] for _ in range(n + 1)]\n",
        "    for i in range(1, n + 1):\n",
        "        for w in range(int(capacity * 100) + 1):\n",
        "            weight = int(weights[i - 1] * 100)\n",
        "            if weight <= w:\n",
        "                dp[i][w] = max(values[i - 1] + dp[i - 1][w - weight], dp[i - 1][w])\n",
        "            else:\n",
        "                dp[i][w] = dp[i - 1][w]\n",
        "    selected = []\n",
        "    w = int(capacity * 100)\n",
        "    for i in range(n, 0, -1):\n",
        "        if dp[i][w] != dp[i - 1][w]:\n",
        "            selected.append(i - 1)\n",
        "            w -= int(weights[i - 1] * 100)\n",
        "    return selected[::-1]\n",
        "\n",
        "# ========= 4Ô∏è‚É£ Paths and Settings =========\n",
        "video_list = [\n",
        "    \"Jumps\", \"Base Jumping\", \"Air_Force_One\", \"Bearpark_climbing\", \"Bike Polo\",\n",
        "    \"Bus_in_Rock_Tunnel\", \"car_over_camera\", \"Car_railcrossing\", \"Cockpit_Landing\", \"Cooking\",\n",
        "    \"Eiffel Tower\", \"Excavators river crossing\", \"Fire Domino\", \"Kids_playing_in_leaves\",\n",
        "    \"Notre_Dame\", \"Paintball\", \"paluma_jump\", \"playing_ball\", \"Playing_on_water_slide\",\n",
        "    \"Saving dolphines\", \"Scuba\", \"St Maarten Landing\", \"Statue of Liberty\", \"Valparaiso_Downhill\"\n",
        "]\n",
        "\n",
        "FEATURES_DIR = \"/mnt/d/Mass Projects/Video_Summ/extracted_features/\"\n",
        "MAT_DIR = \"/mnt/d/Mass Projects/Video_Summ/mat/\"\n",
        "CHUNK_SIZE = 500\n",
        "PENALTY = 500\n",
        "FPS = 25\n",
        "SUMMARY_EXCEL = \"/mnt/d/Mass Projects/Video_Summ/RESULTS/Results_2/SUMME/bilstm_soft_attention_35K.xlsx\"\n",
        "\n",
        "# ========= 5Ô∏è‚É£ Evaluate Videos =========\n",
        "with pd.ExcelWriter(SUMMARY_EXCEL, engine=\"xlsxwriter\") as writer:\n",
        "    summary_data = []\n",
        "\n",
        "    for VIDEO_NAME in video_list:\n",
        "        print(f\"\\n==============================\\nüöÄ Processing video: {VIDEO_NAME}\\n==============================\")\n",
        "\n",
        "        feats_path = os.path.join(FEATURES_DIR, f\"{VIDEO_NAME}.npy\")\n",
        "        mat_path = os.path.join(MAT_DIR, f\"{VIDEO_NAME}.mat\")\n",
        "        if not os.path.exists(feats_path) or not os.path.exists(mat_path):\n",
        "            print(\"‚ùå Missing files. Skipping...\")\n",
        "            continue\n",
        "\n",
        "        raw_feats = np.load(feats_path)\n",
        "        num_frames = raw_feats.shape[0]\n",
        "        video_feats = raw_feats[np.newaxis, ...]\n",
        "\n",
        "        recon = np.zeros_like(video_feats)\n",
        "        for i in range((num_frames + CHUNK_SIZE - 1) // CHUNK_SIZE):\n",
        "            s, e = i * CHUNK_SIZE, min((i + 1) * CHUNK_SIZE, num_frames)\n",
        "            recon[:, s:e, :] = model.predict(video_feats[:, s:e, :], verbose=0)\n",
        "\n",
        "        print(\"‚úÖ Features reconstructed\")\n",
        "\n",
        "        errs = np.mean(np.abs(video_feats - recon), axis=2).flatten()\n",
        "        imp_scores = (errs - errs.min()) / (errs.max() - errs.min())\n",
        "\n",
        "        model_segments = detect_kts_segments(raw_feats, penalty=PENALTY)\n",
        "        segment_durations = [(end - start + 1) / FPS for start, end in model_segments]\n",
        "        segment_scores = [np.mean(imp_scores[start:end + 1]) for start, end in model_segments]\n",
        "\n",
        "        total_duration = num_frames / FPS\n",
        "        summary_duration = total_duration * 0.15\n",
        "        selected_indices = knapsack(segment_scores, segment_durations, summary_duration)\n",
        "        selected_model_segments = [model_segments[i] for i in selected_indices]\n",
        "\n",
        "        mat = scipy.io.loadmat(mat_path)\n",
        "        user_scores = mat['user_score']\n",
        "        num_users = user_scores.shape[1]\n",
        "        all_user_metrics = []\n",
        "\n",
        "        for u in range(num_users):\n",
        "            usr = user_scores[:, u]\n",
        "            nonzero_indices = np.where(usr > 0)[0]\n",
        "            user_segments = get_segments_from_indices(nonzero_indices.tolist())\n",
        "\n",
        "            f1, precision, recall = calculate_segment_f1(user_segments, selected_model_segments)\n",
        "            all_user_metrics.append((u + 1, f1, precision, recall))\n",
        "\n",
        "        df = pd.DataFrame(all_user_metrics, columns=[\"User\", \"F1 Score\", \"Precision\", \"Recall\"])\n",
        "        df.to_excel(writer, sheet_name=VIDEO_NAME[:31], index=False)\n",
        "\n",
        "        summary_data.append({\n",
        "            \"Video\": VIDEO_NAME,\n",
        "            \"KTS Segments\": len(model_segments),\n",
        "            \"Selected\": len(selected_model_segments),\n",
        "            \"Penalty\": PENALTY,\n",
        "            \"Min F1\": df[\"F1 Score\"].min(),\n",
        "            \"Avg F1\": df[\"F1 Score\"].mean(),\n",
        "            \"Max F1\": df[\"F1 Score\"].max(),\n",
        "            \"Min Precision\": df[\"Precision\"].min(),\n",
        "            \"Avg Precision\": df[\"Precision\"].mean(),\n",
        "            \"Max Precision\": df[\"Precision\"].max(),\n",
        "            \"Min Recall\": df[\"Recall\"].min(),\n",
        "            \"Avg Recall\": df[\"Recall\"].mean(),\n",
        "            \"Max Recall\": df[\"Recall\"].max(),\n",
        "        })\n",
        "\n",
        "        del video_feats, recon\n",
        "        gc.collect()\n",
        "        tf.keras.backend.clear_session()\n",
        "\n",
        "    pd.DataFrame(summary_data).to_excel(writer, sheet_name=\"Summary\", index=False)\n",
        "    print(f\"\\n‚úÖ All results saved to: {SUMMARY_EXCEL}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22243a5e",
      "metadata": {
        "id": "22243a5e"
      },
      "source": [
        "# SOFT Attention - TVSUM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a88308d",
      "metadata": {
        "id": "0a88308d"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import h5py\n",
        "import gc\n",
        "import ruptures as rpt\n",
        "\n",
        "# ========= 1Ô∏è‚É£ Register Custom Classes =========\n",
        "@tf.keras.utils.register_keras_serializable()\n",
        "class SoftAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self):\n",
        "        super(SoftAttention, self).__init__()\n",
        "        self.W = tf.keras.layers.Dense(1, activation='tanh')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        score = self.W(inputs)  # (batch, time, 1)\n",
        "        attn_weights = tf.nn.softmax(score, axis=1)  # normalize across time\n",
        "        context = attn_weights * inputs\n",
        "        context = tf.reduce_sum(context, axis=1, keepdims=True)  # (batch, 1, features)\n",
        "        context_repeated = tf.tile(context, [1, tf.shape(inputs)[1], 1])\n",
        "        return context_repeated\n",
        "\n",
        "\n",
        "@tf.keras.utils.register_keras_serializable()\n",
        "class BiLSTMSoftAttentionModel(tf.keras.Model):\n",
        "    def __init__(self, feature_dim=2048, lstm_units=64, **kwargs):\n",
        "        super(BiLSTMSoftAttentionModel, self).__init__(**kwargs)\n",
        "        self.bilstm = tf.keras.layers.Bidirectional(\n",
        "            tf.keras.layers.LSTM(lstm_units, return_sequences=True)\n",
        "        )\n",
        "        self.attention = SoftAttention()\n",
        "        self.reconstruction_layer = tf.keras.layers.TimeDistributed(\n",
        "            tf.keras.layers.Dense(feature_dim, activation=\"linear\")\n",
        "        )\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.bilstm(inputs)\n",
        "        context = self.attention(x)\n",
        "        x = x + context  # residual addition\n",
        "        reconstructed = self.reconstruction_layer(x)\n",
        "        return reconstructed\n",
        "\n",
        "\n",
        "# ========= 2Ô∏è‚É£ Load Model =========\n",
        "MODEL_PATH = \"/mnt/d/Mass Projects/Video_Summ/RESULTS/MODELS/bilstm_soft_attention_15k.keras\"\n",
        "\n",
        "with tf.keras.utils.custom_object_scope({\n",
        "    \"BiLSTMSoftAttentionModel\": BiLSTMSoftAttentionModel,\n",
        "    \"SoftAttention\": SoftAttention\n",
        "}):\n",
        "    model = tf.keras.models.load_model(MODEL_PATH)\n",
        "\n",
        "print(\"\\n‚úÖ BiLSTM + Soft Attention Model loaded successfully\")\n",
        "\n",
        "# ========= 3Ô∏è‚É£ Helper Functions =========\n",
        "def get_segments_from_indices(indices):\n",
        "    if not indices:\n",
        "        return []\n",
        "    indices = sorted(set(indices))\n",
        "    segments, start = [], indices[0]\n",
        "    for i in range(1, len(indices)):\n",
        "        if indices[i] != indices[i - 1] + 1:\n",
        "            segments.append((start, indices[i - 1]))\n",
        "            start = indices[i]\n",
        "    segments.append((start, indices[-1]))\n",
        "    return segments\n",
        "\n",
        "def expand_segment(seg):\n",
        "    return list(range(seg[0], seg[1] + 1))\n",
        "\n",
        "def calculate_segment_f1(user_segments, model_segments):\n",
        "    tp = 0\n",
        "    for m_seg in model_segments:\n",
        "        m_range = set(expand_segment(m_seg))\n",
        "        for u_seg in user_segments:\n",
        "            u_range = set(expand_segment(u_seg))\n",
        "            if m_range & u_range:\n",
        "                tp += 1\n",
        "                break\n",
        "    precision = tp / len(model_segments) if model_segments else 0\n",
        "    recall = tp / len(user_segments) if user_segments else 0\n",
        "    f1 = 2 * precision * recall / (precision + recall) if precision + recall else 0\n",
        "    return f1, precision, recall\n",
        "\n",
        "def detect_kts_segments(features, penalty=500):\n",
        "    algo = rpt.KernelCPD(kernel=\"linear\").fit(features)\n",
        "    change_points = algo.predict(pen=penalty)\n",
        "    change_points = [int(cp) for cp in change_points]\n",
        "    scene_segments, start_frame = [], 0\n",
        "    for cp in change_points:\n",
        "        scene_segments.append((start_frame, cp - 1))\n",
        "        start_frame = cp\n",
        "    if scene_segments[-1][1] < features.shape[0] - 1:\n",
        "        scene_segments.append((start_frame, features.shape[0] - 1))\n",
        "    return scene_segments\n",
        "\n",
        "def knapsack(values, weights, capacity):\n",
        "    n = len(values)\n",
        "    dp = [[0 for _ in range(int(capacity * 100) + 1)] for _ in range(n + 1)]\n",
        "    for i in range(1, n + 1):\n",
        "        for w in range(int(capacity * 100) + 1):\n",
        "            weight = int(weights[i - 1] * 100)\n",
        "            if weight <= w:\n",
        "                dp[i][w] = max(values[i - 1] + dp[i - 1][w - weight], dp[i - 1][w])\n",
        "            else:\n",
        "                dp[i][w] = dp[i - 1][w]\n",
        "    selected = []\n",
        "    w = int(capacity * 100)\n",
        "    for i in range(n, 0, -1):\n",
        "        if dp[i][w] != dp[i - 1][w]:\n",
        "            selected.append(i - 1)\n",
        "            w -= int(weights[i - 1] * 100)\n",
        "    return selected[::-1]\n",
        "\n",
        "# ========= 4Ô∏è‚É£ TVSum Dataset Paths =========\n",
        "FEATURES_DIR = \"/mnt/d/Mass Projects/Video_Summ/TVSUM/RandomSplit_Dataset/resnet_npy/extracted_features_25fps_videos\"\n",
        "MAT_FILE_PATH = \"/mnt/d/Mass Projects/Video_Summ/ydata-tvsum50-v1_1/ydata-tvsum50-matlab/matlab/ydata-tvsum50.mat\"\n",
        "EXCEL_OUT = \"/mnt/d/Mass Projects/Video_Summ/RESULTS/RESULTS/TVSUM/bilstm_soft_attention_15k.xlsx\"\n",
        "FPS = 25\n",
        "PENALTY = 500\n",
        "CHUNK_SIZE = 500\n",
        "\n",
        "# ========= 5Ô∏è‚É£ Load TVSum .mat File =========\n",
        "with h5py.File(MAT_FILE_PATH, \"r\") as mat_data:\n",
        "    tvsum50_group = mat_data[\"tvsum50\"]\n",
        "\n",
        "    def decode_str(ref):\n",
        "        return \"\".join(map(chr, mat_data[ref][()].flatten())).replace(\"\\x00\", \"\")\n",
        "\n",
        "    video_names = [decode_str(ref) for ref in tvsum50_group[\"video\"][:, 0]]\n",
        "    user_annos = [mat_data[ref][:] for ref in tvsum50_group[\"user_anno\"][:, 0]]\n",
        "    nframes_list = [int(mat_data[ref][()][0, 0]) for ref in tvsum50_group[\"nframes\"][:, 0]]\n",
        "\n",
        "# ========= 6Ô∏è‚É£ Evaluation Loop =========\n",
        "with pd.ExcelWriter(EXCEL_OUT, engine=\"xlsxwriter\") as writer:\n",
        "    summary_data = []\n",
        "\n",
        "    for idx, video_name in enumerate(video_names):\n",
        "        print(f\"\\nüöÄ Evaluating video: {video_name}\")\n",
        "\n",
        "        feature_path = os.path.join(FEATURES_DIR, f\"{video_name}.npy\")\n",
        "        if not os.path.exists(feature_path):\n",
        "            print(f\"‚ùå Missing feature file: {video_name}\")\n",
        "            continue\n",
        "\n",
        "        raw_feats = np.load(feature_path)\n",
        "        num_frames = raw_feats.shape[0]\n",
        "        video_feats = raw_feats[np.newaxis, ...]\n",
        "\n",
        "        # Reconstruct in chunks\n",
        "        recon = np.zeros_like(video_feats)\n",
        "        for i in range((num_frames + CHUNK_SIZE - 1) // CHUNK_SIZE):\n",
        "            s, e = i * CHUNK_SIZE, min((i + 1) * CHUNK_SIZE, num_frames)\n",
        "            recon[:, s:e, :] = model.predict(video_feats[:, s:e, :], verbose=0)\n",
        "\n",
        "        # Compute importance\n",
        "        errs = np.mean(np.abs(video_feats - recon), axis=2).flatten()\n",
        "        imp_scores = (errs - errs.min()) / (errs.max() - errs.min())\n",
        "\n",
        "        # KTS segmentation + knapsack selection\n",
        "        model_segments = detect_kts_segments(raw_feats, penalty=PENALTY)\n",
        "        segment_durations = [(end - start + 1) / FPS for start, end in model_segments]\n",
        "        segment_scores = [np.mean(imp_scores[start:end + 1]) for start, end in model_segments]\n",
        "\n",
        "        total_duration = num_frames / FPS\n",
        "        summary_duration = total_duration * 0.15\n",
        "        selected_indices = knapsack(segment_scores, segment_durations, summary_duration)\n",
        "        selected_model_segments = [model_segments[i] for i in selected_indices]\n",
        "\n",
        "        # Evaluate per-user\n",
        "        user_scores = user_annos[idx]\n",
        "        num_users = user_scores.shape[0]\n",
        "        all_user_metrics = []\n",
        "\n",
        "        for u in range(num_users):\n",
        "            user_score = user_scores[u]\n",
        "            k = int(np.floor(num_frames * 0.15))\n",
        "            selected_indices = np.argsort(user_score)[-k:]\n",
        "            user_segments = get_segments_from_indices(selected_indices.tolist())\n",
        "\n",
        "            f1, precision, recall = calculate_segment_f1(user_segments, selected_model_segments)\n",
        "            all_user_metrics.append((u + 1, f1, precision, recall))\n",
        "\n",
        "        df = pd.DataFrame(all_user_metrics, columns=[\"User\", \"F1 Score\", \"Precision\", \"Recall\"])\n",
        "        df.to_excel(writer, sheet_name=video_name[:31], index=False)\n",
        "\n",
        "        summary_data.append({\n",
        "            \"Video\": video_name,\n",
        "            \"KTS Segments\": len(model_segments),\n",
        "            \"Selected\": len(selected_model_segments),\n",
        "            \"Min F1\": df[\"F1 Score\"].min(),\n",
        "            \"Avg F1\": df[\"F1 Score\"].mean(),\n",
        "            \"Max F1\": df[\"F1 Score\"].max(),\n",
        "            \"Min Precision\": df[\"Precision\"].min(),\n",
        "            \"Avg Precision\": df[\"Precision\"].mean(),\n",
        "            \"Max Precision\": df[\"Precision\"].max(),\n",
        "            \"Min Recall\": df[\"Recall\"].min(),\n",
        "            \"Avg Recall\": df[\"Recall\"].mean(),\n",
        "            \"Max Recall\": df[\"Recall\"].max()\n",
        "        })\n",
        "\n",
        "        del video_feats, recon\n",
        "        gc.collect()\n",
        "        tf.keras.backend.clear_session()\n",
        "\n",
        "    pd.DataFrame(summary_data).to_excel(writer, sheet_name=\"Summary\", index=False)\n",
        "    print(f\"\\n‚úÖ TVSum results saved to: {EXCEL_OUT}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15697da0",
      "metadata": {
        "id": "15697da0"
      },
      "source": [
        "# VAE BILSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38c04ac0",
      "metadata": {
        "id": "38c04ac0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "\n",
        "# =======================\n",
        "# 1Ô∏è‚É£ GPU Memory Optimization\n",
        "# =======================\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        print(\"‚úÖ GPU Memory Growth Enabled\")\n",
        "    except RuntimeError as e:\n",
        "        print(e)\n",
        "\n",
        "# Enable mixed precision\n",
        "tf.keras.mixed_precision.set_global_policy(\"mixed_float16\")\n",
        "\n",
        "# =======================\n",
        "# 2Ô∏è‚É£ Load Features with Sliding Windows\n",
        "# =======================\n",
        "base_path = \"/mnt/d/Mass Projects/Video_Summ/new_dataset_features_npy_1750\"\n",
        "train_path = os.path.join(base_path, \"train\")\n",
        "valid_path = os.path.join(base_path, \"valid\")\n",
        "\n",
        "SEQ_LEN = 150\n",
        "STRIDE = 125\n",
        "FEATURE_DIM = 2048\n",
        "\n",
        "def load_features(directory):\n",
        "    all_windows = []\n",
        "    video_files = sorted(os.listdir(directory))\n",
        "    for file in video_files:\n",
        "        file_path = os.path.join(directory, file)\n",
        "        features = np.load(file_path)  # (1750, 2048)\n",
        "\n",
        "        # Sliding windows\n",
        "        for start in range(0, len(features) - SEQ_LEN + 1, STRIDE):\n",
        "            window = features[start:start+SEQ_LEN]\n",
        "            all_windows.append(window)\n",
        "    return np.array(all_windows, dtype=np.float32)\n",
        "\n",
        "print(\"üì• Loading dataset...\")\n",
        "train_features = load_features(train_path)\n",
        "valid_features = load_features(valid_path)\n",
        "print(\"Train windows:\", train_features.shape)\n",
        "print(\"Valid windows:\", valid_features.shape)\n",
        "\n",
        "NUM_EPOCHS = 50\n",
        "BATCH_SIZE = 1\n",
        "LEARNING_RATE = 1e-4\n",
        "MODEL_SAVE_PATH = \"/mnt/d/Mass Projects/Video_Summ/RESULTS/Models_2/SUMME/bilstm_VAE_30k.keras\"\n",
        "os.makedirs(os.path.dirname(MODEL_SAVE_PATH), exist_ok=True)\n",
        "\n",
        "# =======================\n",
        "# 3Ô∏è‚É£ Define BiLSTM + Attention VAE Model\n",
        "# =======================\n",
        "class BiLSTMAttentionVAE(models.Model):\n",
        "    def __init__(self, feature_dim, latent_dim=128, num_heads=2, lstm_units=64, **kwargs):\n",
        "        super(BiLSTMAttentionVAE, self).__init__(**kwargs)\n",
        "        self.feature_dim = feature_dim\n",
        "        self.latent_dim = latent_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.lstm_units = lstm_units\n",
        "\n",
        "        # Encoder\n",
        "        self.bilstm = layers.Bidirectional(layers.LSTM(lstm_units, return_sequences=True))\n",
        "        self.attention = layers.MultiHeadAttention(num_heads=num_heads, key_dim=feature_dim // num_heads)\n",
        "\n",
        "        # Latent projection\n",
        "        self.mu = layers.Dense(latent_dim)\n",
        "        self.logvar = layers.Dense(latent_dim)\n",
        "\n",
        "        # Decoder\n",
        "        self.decoder = layers.TimeDistributed(layers.Dense(feature_dim, activation=\"linear\"))\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        eps = tf.random.normal(shape=tf.shape(mu), dtype=mu.dtype)\n",
        "        return mu + tf.exp(0.5 * logvar) * eps\n",
        "\n",
        "    def call(self, inputs):\n",
        "        h = self.bilstm(inputs)\n",
        "        h = self.attention(h, h)\n",
        "\n",
        "        mu, logvar = self.mu(h), self.logvar(h)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "\n",
        "        recon = self.decoder(z)\n",
        "        return recon, mu, logvar\n",
        "\n",
        "    # üîß Add this so Keras can save/load properly\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"feature_dim\": self.feature_dim,\n",
        "            \"latent_dim\": self.latent_dim,\n",
        "            \"num_heads\": self.num_heads,\n",
        "            \"lstm_units\": self.lstm_units,\n",
        "        })\n",
        "        return config\n",
        "\n",
        "    @classmethod\n",
        "    def from_config(cls, config):\n",
        "        return cls(**config)\n",
        "\n",
        "\n",
        "# =======================\n",
        "# 4Ô∏è‚É£ Custom Loss (Reconstruction + KL Divergence)\n",
        "# =======================\n",
        "@tf.function\n",
        "def vae_loss(y_true, y_pred, mu, logvar):\n",
        "    # Force float32 for stability\n",
        "    y_true = tf.cast(y_true, tf.float32)\n",
        "    y_pred = tf.cast(y_pred, tf.float32)\n",
        "    mu = tf.cast(mu, tf.float32)\n",
        "    logvar = tf.cast(logvar, tf.float32)\n",
        "\n",
        "    # Reconstruction loss\n",
        "    recon_loss = tf.reduce_mean(tf.square(y_true - y_pred))\n",
        "\n",
        "    # KL divergence\n",
        "    kl_loss = -0.5 * tf.reduce_mean(1 + logvar - tf.square(mu) - tf.exp(logvar))\n",
        "\n",
        "    return recon_loss + 0.01 * kl_loss, recon_loss, kl_loss\n",
        "\n",
        "\n",
        "# =======================\n",
        "# 5Ô∏è‚É£ Training Loop (Custom, not model.fit)\n",
        "# =======================\n",
        "model = BiLSTMAttentionVAE(feature_dim=FEATURE_DIM)\n",
        "\n",
        "optimizer = optimizers.Adam(learning_rate=LEARNING_RATE)\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(train_features).batch(BATCH_SIZE).shuffle(100)\n",
        "valid_dataset = tf.data.Dataset.from_tensor_slices(valid_features).batch(BATCH_SIZE)\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    # Training\n",
        "    train_losses = []\n",
        "    for batch in train_dataset:\n",
        "        with tf.GradientTape() as tape:\n",
        "            recon, mu, logvar = model(batch)\n",
        "            loss, recon_loss, kl_loss = vae_loss(batch, recon, mu, logvar)\n",
        "        grads = tape.gradient(loss, model.trainable_variables)\n",
        "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "        train_losses.append(loss.numpy())\n",
        "\n",
        "    # Validation\n",
        "    val_losses = []\n",
        "    for batch in valid_dataset:\n",
        "        recon, mu, logvar = model(batch)\n",
        "        loss, _, _ = vae_loss(batch, recon, mu, logvar)\n",
        "        val_losses.append(loss.numpy())\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{NUM_EPOCHS} | Train Loss: {np.mean(train_losses):.4f} | Val Loss: {np.mean(val_losses):.4f}\")\n",
        "\n",
        "# =======================\n",
        "# 6Ô∏è‚É£ Save & Reload\n",
        "# =======================\n",
        "model.save(MODEL_SAVE_PATH)\n",
        "print(f\"‚úÖ Model saved at {MODEL_SAVE_PATH}\")\n",
        "\n",
        "with tf.keras.utils.custom_object_scope({\"BiLSTMAttentionVAE\": BiLSTMAttentionVAE}):\n",
        "    model = tf.keras.models.load_model(MODEL_SAVE_PATH)\n",
        "\n",
        "print(\"üîÑ Model loaded for evaluation.\")\n",
        "\n",
        "# Example Evaluation\n",
        "test_video = valid_features[0:1]\n",
        "recon, mu, logvar = model(test_video)\n",
        "print(\"Reconstructed Features Shape:\", recon.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32c3ca0e",
      "metadata": {
        "id": "32c3ca0e"
      },
      "source": [
        "# VAE - SUMME"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ab43acd",
      "metadata": {
        "id": "3ab43acd"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import scipy.io\n",
        "import ruptures as rpt\n",
        "import pandas as pd\n",
        "import gc\n",
        "\n",
        "# ========= 1Ô∏è‚É£ Define Trained Model Class (same as training) =========\n",
        "SEQ_LEN = 150\n",
        "FEATURE_DIM = 2048\n",
        "\n",
        "class BiLSTM_VAE_Attention(tf.keras.Model):\n",
        "    def __init__(self, feature_dim, latent_dim=256, lstm_units=64, num_heads=2, **kwargs):\n",
        "        super(BiLSTM_VAE_Attention, self).__init__(**kwargs)\n",
        "        self.feature_dim = feature_dim\n",
        "        self.latent_dim = latent_dim\n",
        "        self.lstm_units = lstm_units\n",
        "        self.num_heads = num_heads\n",
        "\n",
        "        self.bilstm_enc = tf.keras.layers.Bidirectional(\n",
        "            tf.keras.layers.LSTM(lstm_units, return_sequences=True, dtype=\"float32\")\n",
        "        )\n",
        "        self.attention = tf.keras.layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=feature_dim // num_heads, dtype=\"float32\"\n",
        "        )\n",
        "        self.flatten = tf.keras.layers.Flatten(dtype=\"float32\")\n",
        "        self.mu_dense = tf.keras.layers.Dense(latent_dim, dtype=\"float32\")\n",
        "        self.logvar_dense = tf.keras.layers.Dense(latent_dim, dtype=\"float32\")\n",
        "\n",
        "        self.decoder_dense = tf.keras.layers.Dense(SEQ_LEN * feature_dim, activation=\"linear\", dtype=\"float32\")\n",
        "        self.reshape_layer = tf.keras.layers.Reshape((SEQ_LEN, feature_dim))\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        eps = tf.random.normal(shape=tf.shape(mu), dtype=mu.dtype)\n",
        "        return mu + tf.exp(0.5 * logvar) * eps\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = tf.cast(inputs, tf.float32)\n",
        "        x = self.bilstm_enc(x)\n",
        "        x = self.attention(x, x)\n",
        "        flat = self.flatten(x)\n",
        "        mu = self.mu_dense(flat)\n",
        "        logvar = self.logvar_dense(flat)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        decoded = self.decoder_dense(z)\n",
        "        reconstructed = self.reshape_layer(decoded)\n",
        "        kl_loss = -0.5 * tf.reduce_mean(1 + logvar - tf.square(mu) - tf.exp(logvar))\n",
        "        self.add_loss(kl_loss)\n",
        "        return reconstructed\n",
        "\n",
        "\n",
        "# ========= 2Ô∏è‚É£ Load Trained Model =========\n",
        "MODEL_PATH = \"/mnt/d/Mass Projects/Video_Summ/RESULTS/MODELS/bilstm_VAE_60k.keras\"\n",
        "\n",
        "with tf.keras.utils.custom_object_scope({\"BiLSTM_VAE_Attention\": BiLSTM_VAE_Attention}):\n",
        "    model = tf.keras.models.load_model(MODEL_PATH)\n",
        "\n",
        "print(\"\\n‚úÖ BiLSTM + Multi-Head Attention + VAE model loaded successfully\")\n",
        "\n",
        "# ========= 3Ô∏è‚É£ Helper Functions =========\n",
        "def get_segments_from_indices(indices):\n",
        "    if not indices:\n",
        "        return []\n",
        "    indices = sorted(set(indices))\n",
        "    segments, start = [], indices[0]\n",
        "    for i in range(1, len(indices)):\n",
        "        if indices[i] != indices[i - 1] + 1:\n",
        "            segments.append((start, indices[i - 1]))\n",
        "            start = indices[i]\n",
        "    segments.append((start, indices[-1]))\n",
        "    return segments\n",
        "\n",
        "def expand_segment(seg):\n",
        "    return list(range(seg[0], seg[1] + 1))\n",
        "\n",
        "def calculate_segment_f1(user_segments, model_segments):\n",
        "    tp = 0\n",
        "    for m_seg in model_segments:\n",
        "        m_range = set(expand_segment(m_seg))\n",
        "        for u_seg in user_segments:\n",
        "            u_range = set(expand_segment(u_seg))\n",
        "            if m_range & u_range:\n",
        "                tp += 1\n",
        "                break\n",
        "    precision = tp / len(model_segments) if model_segments else 0\n",
        "    recall = tp / len(user_segments) if user_segments else 0\n",
        "    f1 = 2 * precision * recall / (precision + recall) if precision + recall else 0\n",
        "    return f1, precision, recall\n",
        "\n",
        "def detect_kts_segments(features, penalty=500):\n",
        "    algo = rpt.KernelCPD(kernel=\"linear\").fit(features)\n",
        "    cps = algo.predict(pen=penalty)\n",
        "    segments, start = [], 0\n",
        "    for cp in cps:\n",
        "        segments.append((start, cp - 1))\n",
        "        start = cp\n",
        "    if segments[-1][1] < features.shape[0] - 1:\n",
        "        segments.append((start, features.shape[0] - 1))\n",
        "    return segments\n",
        "\n",
        "def knapsack(values, weights, capacity):\n",
        "    n = len(values)\n",
        "    dp = [[0 for _ in range(int(capacity * 100) + 1)] for _ in range(n + 1)]\n",
        "    for i in range(1, n + 1):\n",
        "        for w in range(int(capacity * 100) + 1):\n",
        "            weight = int(weights[i - 1] * 100)\n",
        "            if weight <= w:\n",
        "                dp[i][w] = max(values[i - 1] + dp[i - 1][w - weight], dp[i - 1][w])\n",
        "            else:\n",
        "                dp[i][w] = dp[i - 1][w]\n",
        "    selected = []\n",
        "    w = int(capacity * 100)\n",
        "    for i in range(n, 0, -1):\n",
        "        if dp[i][w] != dp[i - 1][w]:\n",
        "            selected.append(i - 1)\n",
        "            w -= int(weights[i - 1] * 100)\n",
        "    return selected[::-1]\n",
        "\n",
        "\n",
        "# ========= 4Ô∏è‚É£ Paths and Settings =========\n",
        "video_list = [\n",
        "    \"Jumps\", \"Base Jumping\", \"Air_Force_One\", \"Bearpark_climbing\", \"Bike Polo\",\n",
        "    \"Bus_in_Rock_Tunnel\", \"car_over_camera\", \"Car_railcrossing\", \"Cockpit_Landing\", \"Cooking\",\n",
        "    \"Eiffel Tower\", \"Excavators river crossing\", \"Fire Domino\", \"Kids_playing_in_leaves\",\n",
        "    \"Notre_Dame\", \"Paintball\", \"paluma_jump\", \"playing_ball\", \"Playing_on_water_slide\",\n",
        "    \"Saving dolphines\", \"Scuba\", \"St Maarten Landing\", \"Statue of Liberty\", \"Valparaiso_Downhill\"\n",
        "]\n",
        "\n",
        "FEATURES_DIR = \"/mnt/d/Mass Projects/Video_Summ/extracted_features/\"\n",
        "MAT_DIR = \"/mnt/d/Mass Projects/Video_Summ/mat/\"\n",
        "CHUNK_SIZE = 500\n",
        "PENALTY = 500\n",
        "FPS = 25\n",
        "SUMMARY_EXCEL = \"/mnt/d/Mass Projects/Video_Summ/RESULTS/RESULTS/SUMME/bilstm_VAE_60k.xlsx\"\n",
        "\n",
        "\n",
        "# ========= 5Ô∏è‚É£ Evaluate Videos =========\n",
        "with pd.ExcelWriter(SUMMARY_EXCEL, engine=\"xlsxwriter\") as writer:\n",
        "    summary_data = []\n",
        "\n",
        "    for VIDEO_NAME in video_list:\n",
        "        print(f\"\\n==============================\\nüöÄ Processing video: {VIDEO_NAME}\\n==============================\")\n",
        "\n",
        "        feats_path = os.path.join(FEATURES_DIR, f\"{VIDEO_NAME}.npy\")\n",
        "        mat_path = os.path.join(MAT_DIR, f\"{VIDEO_NAME}.mat\")\n",
        "        if not os.path.exists(feats_path) or not os.path.exists(mat_path):\n",
        "            print(\"‚ùå Missing files. Skipping...\")\n",
        "            continue\n",
        "\n",
        "        raw_feats = np.load(feats_path)\n",
        "        num_frames = raw_feats.shape[0]\n",
        "        video_feats = raw_feats[np.newaxis, ...]\n",
        "\n",
        "        recon = np.zeros_like(video_feats)\n",
        "        for i in range((num_frames + CHUNK_SIZE - 1) // CHUNK_SIZE):\n",
        "            s, e = i * CHUNK_SIZE, min((i + 1) * CHUNK_SIZE, num_frames)\n",
        "            recon[:, s:e, :] = model.predict(video_feats[:, s:e, :], verbose=0)\n",
        "\n",
        "        print(\"‚úÖ Features reconstructed\")\n",
        "\n",
        "        errs = np.mean(np.abs(video_feats - recon), axis=2).flatten()\n",
        "        imp_scores = (errs - errs.min()) / (errs.max() - errs.min())\n",
        "\n",
        "        model_segments = detect_kts_segments(raw_feats, penalty=PENALTY)\n",
        "        segment_durations = [(end - start + 1) / FPS for start, end in model_segments]\n",
        "        segment_scores = [np.mean(imp_scores[start:end + 1]) for start, end in model_segments]\n",
        "\n",
        "        total_duration = num_frames / FPS\n",
        "        summary_duration = total_duration * 0.15\n",
        "        selected_indices = knapsack(segment_scores, segment_durations, summary_duration)\n",
        "        selected_model_segments = [model_segments[i] for i in selected_indices]\n",
        "\n",
        "        mat = scipy.io.loadmat(mat_path)\n",
        "        user_scores = mat['user_score']\n",
        "        num_users = user_scores.shape[1]\n",
        "        all_user_metrics = []\n",
        "\n",
        "        for u in range(num_users):\n",
        "            usr = user_scores[:, u]\n",
        "            nonzero_indices = np.where(usr > 0)[0]\n",
        "            user_segments = get_segments_from_indices(nonzero_indices.tolist())\n",
        "            f1, precision, recall = calculate_segment_f1(user_segments, selected_model_segments)\n",
        "            all_user_metrics.append((u + 1, f1, precision, recall))\n",
        "\n",
        "        df = pd.DataFrame(all_user_metrics, columns=[\"User\", \"F1 Score\", \"Precision\", \"Recall\"])\n",
        "        df.to_excel(writer, sheet_name=VIDEO_NAME[:31], index=False)\n",
        "\n",
        "        summary_data.append({\n",
        "            \"Video\": VIDEO_NAME,\n",
        "            \"KTS Segments\": len(model_segments),\n",
        "            \"Selected\": len(selected_model_segments),\n",
        "            \"Penalty\": PENALTY,\n",
        "            \"Min F1\": df[\"F1 Score\"].min(),\n",
        "            \"Avg F1\": df[\"F1 Score\"].mean(),\n",
        "            \"Max F1\": df[\"F1 Score\"].max(),\n",
        "            \"Min Precision\": df[\"Precision\"].min(),\n",
        "            \"Avg Precision\": df[\"Precision\"].mean(),\n",
        "            \"Max Precision\": df[\"Precision\"].max(),\n",
        "            \"Min Recall\": df[\"Recall\"].min(),\n",
        "            \"Avg Recall\": df[\"Recall\"].mean(),\n",
        "            \"Max Recall\": df[\"Recall\"].max(),\n",
        "        })\n",
        "\n",
        "        del video_feats, recon\n",
        "        gc.collect()\n",
        "        tf.keras.backend.clear_session()\n",
        "\n",
        "    pd.DataFrame(summary_data).to_excel(writer, sheet_name=\"Summary\", index=False)\n",
        "    print(f\"\\n‚úÖ All results saved to: {SUMMARY_EXCEL}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f139084f",
      "metadata": {
        "id": "f139084f"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import scipy.io\n",
        "import ruptures as rpt\n",
        "import pandas as pd\n",
        "import gc\n",
        "\n",
        "# ========= 1. Load Model (VAE) =========\n",
        "class BiLSTMAttentionVAE(tf.keras.Model):\n",
        "    def __init__(self, feature_dim=2048, latent_dim=128, num_heads=2, lstm_units=64, **kwargs):\n",
        "        super(BiLSTMAttentionVAE, self).__init__(**kwargs)\n",
        "        self.feature_dim = feature_dim\n",
        "        self.latent_dim = latent_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.lstm_units = lstm_units\n",
        "\n",
        "        # Encoder\n",
        "        self.bilstm = tf.keras.layers.Bidirectional(\n",
        "            tf.keras.layers.LSTM(lstm_units, return_sequences=True))\n",
        "        self.attention = tf.keras.layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=feature_dim // num_heads)\n",
        "\n",
        "        # Latent space\n",
        "        self.mu = tf.keras.layers.Dense(latent_dim)\n",
        "        self.logvar = tf.keras.layers.Dense(latent_dim)\n",
        "\n",
        "        # Decoder\n",
        "        self.decoder = tf.keras.layers.TimeDistributed(\n",
        "            tf.keras.layers.Dense(feature_dim, activation=\"linear\"))\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        eps = tf.random.normal(shape=tf.shape(mu), dtype=mu.dtype)\n",
        "        return mu + tf.exp(0.5 * logvar) * eps\n",
        "\n",
        "    def call(self, inputs):\n",
        "        h = self.bilstm(inputs)\n",
        "        h = self.attention(h, h)\n",
        "        mu, logvar = self.mu(h), self.logvar(h)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        recon = self.decoder(z)\n",
        "        return recon, mu, logvar\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"feature_dim\": self.feature_dim,\n",
        "            \"latent_dim\": self.latent_dim,\n",
        "            \"num_heads\": self.num_heads,\n",
        "            \"lstm_units\": self.lstm_units,\n",
        "        })\n",
        "        return config\n",
        "\n",
        "    @classmethod\n",
        "    def from_config(cls, config):\n",
        "        return cls(**config)\n",
        "\n",
        "\n",
        "MODEL_PATH = \"/mnt/d/Mass Projects/Video_Summ/RESULTS/MODELS/bilstm_VAE_35k.keras\"\n",
        "with tf.keras.utils.custom_object_scope({\"BiLSTMAttentionVAE\": BiLSTMAttentionVAE}):\n",
        "    model = tf.keras.models.load_model(MODEL_PATH)\n",
        "\n",
        "print(\"\\n‚úÖ VAE model loaded successfully\")\n",
        "\n",
        "# ========= 2. Helper Functions (unchanged) =========\n",
        "def get_segments_from_indices(indices):\n",
        "    if not indices:\n",
        "        return []\n",
        "    indices = sorted(set(indices))\n",
        "    segments, start = [], indices[0]\n",
        "    for i in range(1, len(indices)):\n",
        "        if indices[i] != indices[i - 1] + 1:\n",
        "            segments.append((start, indices[i - 1]))\n",
        "            start = indices[i]\n",
        "    segments.append((start, indices[-1]))\n",
        "    return segments\n",
        "\n",
        "def expand_segment(seg):\n",
        "    return list(range(seg[0], seg[1] + 1))\n",
        "\n",
        "def format_segments(segments):\n",
        "    return [f\"({s})\" if s == e else f\"({s}‚Äì{e})\" for s, e in segments]\n",
        "\n",
        "def print_segments_columnwise(segments, items_per_line=10):\n",
        "    for i in range(0, len(segments), items_per_line):\n",
        "        print(\"  \" + \"  \".join(segments[i:i + items_per_line]))\n",
        "\n",
        "def calculate_segment_f1(user_segments, model_segments):\n",
        "    tp = 0\n",
        "    matched = []\n",
        "    for m_seg in model_segments:\n",
        "        m_range = set(expand_segment(m_seg))\n",
        "        for u_seg in user_segments:\n",
        "            u_range = set(expand_segment(u_seg))\n",
        "            if m_range & u_range:\n",
        "                tp += 1\n",
        "                matched.append(m_seg)\n",
        "                break\n",
        "    precision = tp / len(model_segments) if model_segments else 0\n",
        "    recall = tp / len(user_segments) if user_segments else 0\n",
        "    f1 = 2 * precision * recall / (precision + recall) if precision + recall else 0\n",
        "    return f1, precision, recall, matched\n",
        "\n",
        "def detect_kts_segments(features, penalty=500):\n",
        "    algo = rpt.KernelCPD(kernel=\"linear\").fit(features)\n",
        "    change_points = algo.predict(pen=penalty)\n",
        "    change_points = [int(cp) for cp in change_points]\n",
        "    scene_segments = []\n",
        "    start_frame = 0\n",
        "    for cp in change_points:\n",
        "        scene_segments.append((start_frame, cp - 1))\n",
        "        start_frame = cp\n",
        "    if scene_segments[-1][1] < features.shape[0] - 1:\n",
        "        scene_segments.append((start_frame, features.shape[0] - 1))\n",
        "    return scene_segments\n",
        "\n",
        "def knapsack(values, weights, capacity):\n",
        "    n = len(values)\n",
        "    dp = [[0 for _ in range(int(capacity * 100) + 1)] for _ in range(n + 1)]\n",
        "    for i in range(1, n + 1):\n",
        "        for w in range(int(capacity * 100) + 1):\n",
        "            weight = int(weights[i - 1] * 100)\n",
        "            if weight <= w:\n",
        "                dp[i][w] = max(values[i - 1] + dp[i - 1][w - weight], dp[i - 1][w])\n",
        "            else:\n",
        "                dp[i][w] = dp[i - 1][w]\n",
        "    selected = []\n",
        "    w = int(capacity * 100)\n",
        "    for i in range(n, 0, -1):\n",
        "        if dp[i][w] != dp[i - 1][w]:\n",
        "            selected.append(i - 1)\n",
        "            w -= int(weights[i - 1] * 100)\n",
        "    return selected[::-1]\n",
        "\n",
        "# ========= 3. Process Videos =========\n",
        "video_list = [\n",
        "    \"Jumps\", \"Base Jumping\", \"Air_Force_One\", \"Bearpark_climbing\", \"Bike Polo\",\n",
        "    \"Bus_in_Rock_Tunnel\", \"car_over_camera\", \"Car_railcrossing\", \"Cockpit_Landing\", \"Cooking\",\n",
        "    \"Eiffel Tower\", \"Excavators river crossing\", \"Fire Domino\", \"Kids_playing_in_leaves\",\n",
        "    \"Notre_Dame\", \"Paintball\", \"paluma_jump\", \"playing_ball\", \"Playing_on_water_slide\",\n",
        "    \"Saving dolphines\", \"Scuba\", \"St Maarten Landing\", \"Statue of Liberty\", \"Valparaiso_Downhill\"\n",
        "]\n",
        "\n",
        "FEATURES_DIR = \"/mnt/d/Mass Projects/Video_Summ/extracted_features/\"\n",
        "MAT_DIR = \"/mnt/d/Mass Projects/Video_Summ/mat/\"\n",
        "CHUNK_SIZE = 500\n",
        "PENALTY = 500\n",
        "FPS = 25\n",
        "SUMMARY_EXCEL = \"/mnt/d/Mass Projects/Video_Summ/RESULTS/RESULTS/SUMME/bilstm_VAE_35k.xlsx\"\n",
        "\n",
        "with pd.ExcelWriter(SUMMARY_EXCEL, engine=\"xlsxwriter\") as writer:\n",
        "    summary_data = []\n",
        "\n",
        "    for VIDEO_NAME in video_list:\n",
        "        print(f\"\\n==============================\\nüöÄ Processing video: {VIDEO_NAME}\\n==============================\")\n",
        "\n",
        "        feats_path = os.path.join(FEATURES_DIR, f\"{VIDEO_NAME}.npy\")\n",
        "        mat_path = os.path.join(MAT_DIR, f\"{VIDEO_NAME}.mat\")\n",
        "        if not os.path.exists(feats_path) or not os.path.exists(mat_path):\n",
        "            print(\"‚ùå Skipping, missing file.\")\n",
        "            continue\n",
        "\n",
        "        raw_feats = np.load(feats_path)\n",
        "        num_frames = raw_feats.shape[0]\n",
        "        video_feats = raw_feats[np.newaxis, ...]\n",
        "\n",
        "        recon = np.zeros_like(video_feats)\n",
        "        for i in range((num_frames + CHUNK_SIZE - 1) // CHUNK_SIZE):\n",
        "            s, e = i * CHUNK_SIZE, min((i + 1) * CHUNK_SIZE, num_frames)\n",
        "            # call VAE -> take only reconstruction\n",
        "            r, _, _ = model(video_feats[:, s:e, :])\n",
        "            recon[:, s:e, :] = r.numpy()\n",
        "        print(\"‚úÖ Features reconstructed (VAE)\")\n",
        "\n",
        "        # === scoring & segmentation remain unchanged ===\n",
        "        errs = np.mean(np.abs(video_feats - recon), axis=2).flatten()\n",
        "        imp_scores = (errs - errs.min()) / (errs.max() - errs.min())\n",
        "\n",
        "        model_segments = detect_kts_segments(raw_feats, penalty=PENALTY)\n",
        "        segment_durations = [(end - start + 1) / FPS for start, end in model_segments]\n",
        "        segment_scores = [np.mean(imp_scores[start:end + 1]) for start, end in model_segments]\n",
        "\n",
        "        total_duration = num_frames / FPS\n",
        "        summary_duration = total_duration * 0.15\n",
        "        selected_indices = knapsack(segment_scores, segment_durations, summary_duration)\n",
        "        selected_model_segments = [model_segments[i] for i in selected_indices]\n",
        "\n",
        "        mat = scipy.io.loadmat(mat_path)\n",
        "        user_scores = mat['user_score']\n",
        "        num_users = user_scores.shape[1]\n",
        "        all_user_metrics = []\n",
        "\n",
        "        for u in range(num_users):\n",
        "            usr = user_scores[:, u]\n",
        "            nonzero_indices = np.where(usr > 0)[0]\n",
        "            user_segments = get_segments_from_indices(nonzero_indices.tolist())\n",
        "\n",
        "            f1, precision, recall, _ = calculate_segment_f1(user_segments, selected_model_segments)\n",
        "            all_user_metrics.append((u + 1, f1, precision, recall))\n",
        "\n",
        "        df = pd.DataFrame(all_user_metrics, columns=[\"User\", \"F1 Score\", \"Precision\", \"Recall\"])\n",
        "        df.to_excel(writer, sheet_name=VIDEO_NAME[:31], index=False)\n",
        "\n",
        "        summary_data.append({\n",
        "            \"Video Name\": VIDEO_NAME,\n",
        "            \"KTS Segments\": len(model_segments),\n",
        "            \"Knapsack Selected\": len(selected_model_segments),\n",
        "            \"Penalty\": PENALTY,\n",
        "            \"Min Precision\": df[\"Precision\"].min(),\n",
        "            \"Avg Precision\": df[\"Precision\"].mean(),\n",
        "            \"Max Precision\": df[\"Precision\"].max(),\n",
        "            \"Min Recall\": df[\"Recall\"].min(),\n",
        "            \"Avg Recall\": df[\"Recall\"].mean(),\n",
        "            \"Max Recall\": df[\"Recall\"].max(),\n",
        "            \"Min F1\": df[\"F1 Score\"].min(),\n",
        "            \"Avg F1\": df[\"F1 Score\"].mean(),\n",
        "            \"Max F1\": df[\"F1 Score\"].max(),\n",
        "        })\n",
        "\n",
        "        del video_feats, recon\n",
        "        gc.collect()\n",
        "        tf.keras.backend.clear_session()\n",
        "\n",
        "    pd.DataFrame(summary_data).to_excel(writer, sheet_name=\"Summary\", index=False)\n",
        "    print(f\"\\n‚úÖ All results saved to: {SUMMARY_EXCEL}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf98b903",
      "metadata": {
        "id": "cf98b903"
      },
      "source": [
        "# VAE - TVSUM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77310cea",
      "metadata": {
        "id": "77310cea"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import h5py\n",
        "import ruptures as rpt\n",
        "import gc\n",
        "import scipy.io\n",
        "\n",
        "# ========= 1Ô∏è‚É£ Define & Load VAE Model =========\n",
        "class BiLSTMAttentionVAE(tf.keras.Model):\n",
        "    def __init__(self, feature_dim=2048, latent_dim=128, num_heads=2, lstm_units=64, **kwargs):\n",
        "        super(BiLSTMAttentionVAE, self).__init__(**kwargs)\n",
        "        self.feature_dim = feature_dim\n",
        "        self.latent_dim = latent_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.lstm_units = lstm_units\n",
        "\n",
        "        # Encoder\n",
        "        self.bilstm = tf.keras.layers.Bidirectional(\n",
        "            tf.keras.layers.LSTM(lstm_units, return_sequences=True)\n",
        "        )\n",
        "        self.attention = tf.keras.layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=feature_dim // num_heads\n",
        "        )\n",
        "\n",
        "        # Latent space\n",
        "        self.mu = tf.keras.layers.Dense(latent_dim)\n",
        "        self.logvar = tf.keras.layers.Dense(latent_dim)\n",
        "\n",
        "        # Decoder\n",
        "        self.decoder = tf.keras.layers.TimeDistributed(\n",
        "            tf.keras.layers.Dense(feature_dim, activation=\"linear\")\n",
        "        )\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        eps = tf.random.normal(shape=tf.shape(mu), dtype=mu.dtype)\n",
        "        return mu + tf.exp(0.5 * logvar) * eps\n",
        "\n",
        "    def call(self, inputs):\n",
        "        h = self.bilstm(inputs)\n",
        "        h = self.attention(h, h)\n",
        "        mu, logvar = self.mu(h), self.logvar(h)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        recon = self.decoder(z)\n",
        "        return recon, mu, logvar\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"feature_dim\": self.feature_dim,\n",
        "            \"latent_dim\": self.latent_dim,\n",
        "            \"num_heads\": self.num_heads,\n",
        "            \"lstm_units\": self.lstm_units,\n",
        "        })\n",
        "        return config\n",
        "\n",
        "    @classmethod\n",
        "    def from_config(cls, config):\n",
        "        return cls(**config)\n",
        "\n",
        "\n",
        "MODEL_PATH = \"/mnt/d/Mass Projects/Video_Summ/RESULTS/Models_2/SUMME/bilstm_VAE_60k.keras\"\n",
        "with tf.keras.utils.custom_object_scope({\"BiLSTMAttentionVAE\": BiLSTMAttentionVAE}):\n",
        "    model = tf.keras.models.load_model(MODEL_PATH)\n",
        "print(\"\\n‚úÖ VAE model loaded successfully for TVSum evaluation\")\n",
        "\n",
        "# ========= 2Ô∏è‚É£ Helper Functions =========\n",
        "def get_segments_from_indices(indices):\n",
        "    if not indices:\n",
        "        return []\n",
        "    indices = sorted(set(indices))\n",
        "    segments, start = [], indices[0]\n",
        "    for i in range(1, len(indices)):\n",
        "        if indices[i] != indices[i - 1] + 1:\n",
        "            segments.append((start, indices[i - 1]))\n",
        "            start = indices[i]\n",
        "    segments.append((start, indices[-1]))\n",
        "    return segments\n",
        "\n",
        "def expand_segment(seg):\n",
        "    return list(range(seg[0], seg[1] + 1))\n",
        "\n",
        "def calculate_segment_f1(user_segments, model_segments):\n",
        "    tp = 0\n",
        "    for m_seg in model_segments:\n",
        "        m_range = set(expand_segment(m_seg))\n",
        "        for u_seg in user_segments:\n",
        "            u_range = set(expand_segment(u_seg))\n",
        "            if m_range & u_range:\n",
        "                tp += 1\n",
        "                break\n",
        "    precision = tp / len(model_segments) if model_segments else 0\n",
        "    recall = tp / len(user_segments) if user_segments else 0\n",
        "    f1 = 2 * precision * recall / (precision + recall) if precision + recall else 0\n",
        "    return f1, precision, recall\n",
        "\n",
        "def detect_kts_segments(features, penalty=500):\n",
        "    algo = rpt.KernelCPD(kernel=\"linear\").fit(features)\n",
        "    change_points = algo.predict(pen=penalty)\n",
        "    change_points = [int(cp) for cp in change_points]\n",
        "    segments, start = [], 0\n",
        "    for cp in change_points:\n",
        "        segments.append((start, cp - 1))\n",
        "        start = cp\n",
        "    if segments[-1][1] < features.shape[0] - 1:\n",
        "        segments.append((start, features.shape[0] - 1))\n",
        "    return segments\n",
        "\n",
        "def knapsack(values, weights, capacity):\n",
        "    n = len(values)\n",
        "    dp = [[0 for _ in range(int(capacity * 100) + 1)] for _ in range(n + 1)]\n",
        "    for i in range(1, n + 1):\n",
        "        for w in range(int(capacity * 100) + 1):\n",
        "            weight = int(weights[i - 1] * 100)\n",
        "            if weight <= w:\n",
        "                dp[i][w] = max(values[i - 1] + dp[i - 1][w - weight], dp[i - 1][w])\n",
        "            else:\n",
        "                dp[i][w] = dp[i - 1][w]\n",
        "    selected = []\n",
        "    w = int(capacity * 100)\n",
        "    for i in range(n, 0, -1):\n",
        "        if dp[i][w] != dp[i - 1][w]:\n",
        "            selected.append(i - 1)\n",
        "            w -= int(weights[i - 1] * 100)\n",
        "    return selected[::-1]\n",
        "\n",
        "# ========= 3Ô∏è‚É£ Dataset Paths =========\n",
        "FEATURES_DIR = \"/mnt/d/Mass Projects/Video_Summ/TVSUM/RandomSplit_Dataset/resnet_npy/extracted_features_25fps_videos\"\n",
        "MAT_FILE_PATH = \"/mnt/d/Mass Projects/Video_Summ/ydata-tvsum50-v1_1/ydata-tvsum50-matlab/matlab/ydata-tvsum50.mat\"\n",
        "EXCEL_OUT = \"/mnt/d/Mass Projects/Video_Summ/RESULTS/Results_2/TVSUM/bilstm_VAE_60k.xlsx\"\n",
        "\n",
        "FPS = 25\n",
        "PENALTY = 500\n",
        "CHUNK_SIZE = 500\n",
        "\n",
        "# ========= 4Ô∏è‚É£ Load TVSum .mat File =========\n",
        "with h5py.File(MAT_FILE_PATH, \"r\") as mat_data:\n",
        "    tvsum50 = mat_data[\"tvsum50\"]\n",
        "\n",
        "    def decode_str(ref):\n",
        "        return \"\".join(map(chr, mat_data[ref][()].flatten())).replace(\"\\x00\", \"\")\n",
        "\n",
        "    video_names = [decode_str(ref) for ref in tvsum50[\"video\"][:, 0]]\n",
        "    user_annos = [mat_data[ref][:] for ref in tvsum50[\"user_anno\"][:, 0]]\n",
        "    nframes_list = [int(mat_data[ref][()][0, 0]) for ref in tvsum50[\"nframes\"][:, 0]]\n",
        "\n",
        "# ========= 5Ô∏è‚É£ Evaluation =========\n",
        "with pd.ExcelWriter(EXCEL_OUT, engine=\"xlsxwriter\") as writer:\n",
        "    summary_data = []\n",
        "\n",
        "    for idx, video_name in enumerate(video_names):\n",
        "        print(f\"\\nüöÄ Processing video: {video_name}\")\n",
        "\n",
        "        feature_path = os.path.join(FEATURES_DIR, f\"{video_name}.npy\")\n",
        "        if not os.path.exists(feature_path):\n",
        "            print(f\"‚ùå Missing feature file for {video_name}, skipping...\")\n",
        "            continue\n",
        "\n",
        "        raw_feats = np.load(feature_path)\n",
        "        num_frames = raw_feats.shape[0]\n",
        "        video_feats = raw_feats[np.newaxis, ...]\n",
        "\n",
        "        # === Reconstruction ===\n",
        "        recon = np.zeros_like(video_feats)\n",
        "        for i in range((num_frames + CHUNK_SIZE - 1) // CHUNK_SIZE):\n",
        "            s, e = i * CHUNK_SIZE, min((i + 1) * CHUNK_SIZE, num_frames)\n",
        "            r, _, _ = model(video_feats[:, s:e, :])\n",
        "            recon[:, s:e, :] = r.numpy()\n",
        "        print(\"‚úÖ Features reconstructed\")\n",
        "\n",
        "        # === Importance Scoring ===\n",
        "        errs = np.mean(np.abs(video_feats - recon), axis=2).flatten()\n",
        "        imp_scores = (errs - errs.min()) / (errs.max() - errs.min())\n",
        "\n",
        "        # === KTS + Knapsack ===\n",
        "        model_segments = detect_kts_segments(raw_feats, penalty=PENALTY)\n",
        "        segment_durations = [(end - start + 1) / FPS for start, end in model_segments]\n",
        "        segment_scores = [np.mean(imp_scores[start:end + 1]) for start, end in model_segments]\n",
        "\n",
        "        total_duration = num_frames / FPS\n",
        "        summary_duration = total_duration * 0.15\n",
        "        selected_indices = knapsack(segment_scores, segment_durations, summary_duration)\n",
        "        selected_model_segments = [model_segments[i] for i in selected_indices]\n",
        "\n",
        "        # === Per-user evaluation ===\n",
        "        user_scores = user_annos[idx]\n",
        "        num_users = user_scores.shape[0]\n",
        "        all_user_metrics = []\n",
        "\n",
        "        for u in range(num_users):\n",
        "            user_score = user_scores[u]\n",
        "            k = int(np.floor(num_frames * 0.15))\n",
        "            top_indices = np.argsort(user_score)[-k:]\n",
        "            user_segments = get_segments_from_indices(top_indices.tolist())\n",
        "\n",
        "            f1, precision, recall = calculate_segment_f1(user_segments, selected_model_segments)\n",
        "            all_user_metrics.append((u + 1, f1, precision, recall))\n",
        "\n",
        "        df = pd.DataFrame(all_user_metrics, columns=[\"User\", \"F1 Score\", \"Precision\", \"Recall\"])\n",
        "        df.to_excel(writer, sheet_name=video_name[:31], index=False)\n",
        "\n",
        "        summary_data.append({\n",
        "            \"Video\": video_name,\n",
        "            \"KTS Segments\": len(model_segments),\n",
        "            \"Knapsack Selected\": len(selected_model_segments),\n",
        "            \"Min F1\": df[\"F1 Score\"].min(),\n",
        "            \"Avg F1\": df[\"F1 Score\"].mean(),\n",
        "            \"Max F1\": df[\"F1 Score\"].max(),\n",
        "            \"Min Precision\": df[\"Precision\"].min(),\n",
        "            \"Avg Precision\": df[\"Precision\"].mean(),\n",
        "            \"Max Precision\": df[\"Precision\"].max(),\n",
        "            \"Min Recall\": df[\"Recall\"].min(),\n",
        "            \"Avg Recall\": df[\"Recall\"].mean(),\n",
        "            \"Max Recall\": df[\"Recall\"].max()\n",
        "        })\n",
        "\n",
        "        del video_feats, recon\n",
        "        gc.collect()\n",
        "        tf.keras.backend.clear_session()\n",
        "\n",
        "    pd.DataFrame(summary_data).to_excel(writer, sheet_name=\"Summary\", index=False)\n",
        "    print(f\"\\n‚úÖ All TVSum results saved to: {EXCEL_OUT}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb9e8cac",
      "metadata": {
        "id": "eb9e8cac"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "285b2cac",
      "metadata": {
        "id": "285b2cac"
      },
      "source": [
        "# SELECTOR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16d52fd2",
      "metadata": {
        "id": "16d52fd2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# =======================\n",
        "# 1Ô∏è‚É£ GPU Optimization\n",
        "# =======================\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        print(\"‚úÖ GPU memory growth enabled\")\n",
        "    except RuntimeError as e:\n",
        "        print(e)\n",
        "\n",
        "tf.keras.mixed_precision.set_global_policy(\"mixed_float16\")\n",
        "\n",
        "# =======================\n",
        "# 2Ô∏è‚É£ Dataset Loading (train/valid/test)\n",
        "# =======================\n",
        "BASE_PATH = \"/mnt/d/Mass Projects/Video_Summ/new_dataset_features_npy_1750\"\n",
        "SEQ_LEN = 150\n",
        "STRIDE = 125\n",
        "FEATURE_DIM = 2048\n",
        "\n",
        "def load_features_from_folder(folder_path):\n",
        "    all_windows = []\n",
        "    for fname in sorted(os.listdir(folder_path)):\n",
        "        fpath = os.path.join(folder_path, fname)\n",
        "        if not fname.endswith(\".npy\"):\n",
        "            continue\n",
        "        feats = np.load(fpath)\n",
        "        for start in range(0, len(feats) - SEQ_LEN + 1, STRIDE):\n",
        "            window = feats[start:start+SEQ_LEN]\n",
        "            all_windows.append(window)\n",
        "    return np.array(all_windows, dtype=np.float32)\n",
        "\n",
        "print(\"üì• Loading dataset...\")\n",
        "train_features = load_features_from_folder(os.path.join(BASE_PATH, \"train\"))\n",
        "valid_features = load_features_from_folder(os.path.join(BASE_PATH, \"valid\"))\n",
        "test_features = load_features_from_folder(os.path.join(BASE_PATH, \"test\"))\n",
        "\n",
        "print(\"Train:\", train_features.shape)\n",
        "print(\"Valid:\", valid_features.shape)\n",
        "print(\"Test:\", test_features.shape)\n",
        "\n",
        "# =======================\n",
        "# 3Ô∏è‚É£ Reconstructor Model\n",
        "# =======================\n",
        "class Reconstructor(tf.keras.Model):\n",
        "    def __init__(self, input_dim=2048, hidden_dim=512):\n",
        "        super(Reconstructor, self).__init__()\n",
        "        self.encoder = layers.Bidirectional(\n",
        "            layers.LSTM(hidden_dim, return_sequences=True)\n",
        "        )\n",
        "        self.decoder = layers.Bidirectional(\n",
        "            layers.LSTM(hidden_dim, return_sequences=True)\n",
        "        )\n",
        "        self.output_layer = layers.TimeDistributed(\n",
        "            layers.Dense(input_dim, activation='linear')\n",
        "        )\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.encoder(inputs)\n",
        "        x = self.decoder(x)\n",
        "        return self.output_layer(x)\n",
        "\n",
        "def reconstruction_loss(y_true, y_pred):\n",
        "    return tf.reduce_mean(tf.square(y_true - y_pred))\n",
        "\n",
        "reconstructor = Reconstructor(input_dim=FEATURE_DIM)\n",
        "reconstructor.compile(optimizer=optimizers.Adam(1e-4), loss=reconstruction_loss)\n",
        "\n",
        "print(\"üöÄ Training Reconstructor...\")\n",
        "recon_history = reconstructor.fit(\n",
        "    train_features, train_features,\n",
        "    validation_data=(valid_features, valid_features),\n",
        "    epochs=50, batch_size=2\n",
        ")\n",
        "\n",
        "RECON_PATH = \"/mnt/d/Mass Projects/Video_Summ/RESULTS/MODELS/reconstructor_model_35k.keras\"\n",
        "reconstructor.save(RECON_PATH)\n",
        "print(f\"‚úÖ Reconstructor saved at {RECON_PATH}\")\n",
        "\n",
        "# =======================\n",
        "# 4Ô∏è‚É£ Generate Reconstruction-Based Importance Labels\n",
        "# =======================\n",
        "print(\"‚öôÔ∏è Generating importance labels...\")\n",
        "train_recon = reconstructor.predict(train_features)\n",
        "valid_recon = reconstructor.predict(valid_features)\n",
        "\n",
        "train_err = np.mean(np.square(train_features - train_recon), axis=-1, keepdims=True)\n",
        "valid_err = np.mean(np.square(valid_features - valid_recon), axis=-1, keepdims=True)\n",
        "\n",
        "# Normalize 0‚Äì1\n",
        "train_labels = (train_err - np.min(train_err)) / (np.max(train_err) - np.min(train_err))\n",
        "valid_labels = (valid_err - np.min(valid_err)) / (np.max(valid_err) - np.min(valid_err))\n",
        "\n",
        "print(\"Train Labels:\", train_labels.shape, \"Valid Labels:\", valid_labels.shape)\n",
        "\n",
        "# =======================\n",
        "# 5Ô∏è‚É£ Selector Model\n",
        "# =======================\n",
        "class Selector(tf.keras.Model):\n",
        "    def __init__(self, input_dim=2048, hidden_dim=512):\n",
        "        super(Selector, self).__init__()\n",
        "        self.bilstm = layers.Bidirectional(\n",
        "            layers.LSTM(hidden_dim, return_sequences=True)\n",
        "        )\n",
        "        self.output_layer = layers.TimeDistributed(\n",
        "            layers.Dense(1, activation='sigmoid')\n",
        "        )\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.bilstm(inputs)\n",
        "        return self.output_layer(x)\n",
        "\n",
        "def sparsity_loss(y_true, y_pred):\n",
        "    sigma = 0.7\n",
        "    return tf.abs(tf.reduce_mean(y_pred) - sigma)\n",
        "\n",
        "selector = Selector(input_dim=FEATURE_DIM)\n",
        "selector.compile(optimizer=optimizers.Adam(1e-4), loss=sparsity_loss)\n",
        "\n",
        "print(\"üöÄ Training Selector...\")\n",
        "sel_history = selector.fit(\n",
        "    train_features, train_labels,\n",
        "    validation_data=(valid_features, valid_labels),\n",
        "    epochs=50, batch_size=2\n",
        ")\n",
        "\n",
        "SELECTOR_PATH = \"/mnt/d/Mass Projects/Video_Summ/RESULTS/MODELS/selector_model_35k.keras\"\n",
        "selector.save(SELECTOR_PATH)\n",
        "print(f\"‚úÖ Selector saved at {SELECTOR_PATH}\")\n",
        "\n",
        "# =======================\n",
        "# 6Ô∏è‚É£ Visualize Losses\n",
        "# =======================\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(recon_history.history['loss'], label='Reconstructor Train Loss')\n",
        "plt.plot(recon_history.history['val_loss'], label='Reconstructor Val Loss')\n",
        "plt.legend(); plt.show()\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(sel_history.history['loss'], label='Selector Train Loss')\n",
        "plt.plot(sel_history.history['val_loss'], label='Selector Val Loss')\n",
        "plt.legend(); plt.show()\n",
        "\n",
        "# =======================\n",
        "# 7Ô∏è‚É£ Test Prediction Example\n",
        "# =======================\n",
        "print(\"üîç Generating importance scores on test sample...\")\n",
        "test_video = test_features[0:1]\n",
        "scores = selector.predict(test_video).flatten()\n",
        "print(\"Predicted importance scores:\", scores[:20])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "100a3512",
      "metadata": {
        "id": "100a3512"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "5415553c",
      "metadata": {
        "id": "5415553c"
      },
      "source": [
        "# SELECTOR - SUMME"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3cd99884",
      "metadata": {
        "id": "3cd99884"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import scipy.io\n",
        "import ruptures as rpt\n",
        "import pandas as pd\n",
        "import gc\n",
        "\n",
        "# =====================================\n",
        "# 1Ô∏è‚É£ Define Selector Model (with get_config fix)\n",
        "# =====================================\n",
        "SEQ_LEN = 150\n",
        "FEATURE_DIM = 2048\n",
        "\n",
        "class Selector(tf.keras.Model):\n",
        "    def __init__(self, input_dim=2048, hidden_dim=512, **kwargs):\n",
        "        super(Selector, self).__init__(**kwargs)\n",
        "        self.input_dim_ = input_dim\n",
        "        self.hidden_dim_ = hidden_dim\n",
        "        self.bilstm = tf.keras.layers.Bidirectional(\n",
        "            tf.keras.layers.LSTM(hidden_dim, return_sequences=True, dtype=\"float32\")\n",
        "        )\n",
        "        self.output_layer = tf.keras.layers.TimeDistributed(\n",
        "            tf.keras.layers.Dense(1, activation='sigmoid', dtype=\"float32\")\n",
        "        )\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.bilstm(inputs)\n",
        "        return self.output_layer(x)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"input_dim\": self.input_dim_,\n",
        "            \"hidden_dim\": self.hidden_dim_,\n",
        "        })\n",
        "        return config\n",
        "\n",
        "# =====================================\n",
        "# 2Ô∏è‚É£ Load Pretrained Selector\n",
        "# =====================================\n",
        "SELECTOR_PATH = \"/mnt/d/Mass Projects/Video_Summ/RESULTS/MODELS/selector_model.keras\"\n",
        "\n",
        "selector = Selector(input_dim=FEATURE_DIM, hidden_dim=512)\n",
        "# Build once so weights can load\n",
        "selector.build((None, SEQ_LEN, FEATURE_DIM))\n",
        "\n",
        "try:\n",
        "    # Try as weights first\n",
        "    selector.load_weights(SELECTOR_PATH)\n",
        "    print(\"\\n‚úÖ Selector weights loaded successfully (via load_weights)\")\n",
        "except Exception as e:\n",
        "    print(f\"\\n‚ö†Ô∏è Weight loading failed: {e}\")\n",
        "    print(\"‚û°Ô∏è Trying to load full .keras model...\")\n",
        "    with tf.keras.utils.custom_object_scope({\"Selector\": Selector}):\n",
        "        selector = tf.keras.models.load_model(SELECTOR_PATH)\n",
        "    print(\"\\n‚úÖ Selector model loaded successfully (via load_model fallback)\")\n",
        "\n",
        "# =====================================\n",
        "# 3Ô∏è‚É£ Helper Functions\n",
        "# =====================================\n",
        "def get_segments_from_indices(indices):\n",
        "    if not indices:\n",
        "        return []\n",
        "    indices = sorted(set(indices))\n",
        "    segments, start = [], indices[0]\n",
        "    for i in range(1, len(indices)):\n",
        "        if indices[i] != indices[i - 1] + 1:\n",
        "            segments.append((start, indices[i - 1]))\n",
        "            start = indices[i]\n",
        "    segments.append((start, indices[-1]))\n",
        "    return segments\n",
        "\n",
        "def expand_segment(seg):\n",
        "    return list(range(seg[0], seg[1] + 1))\n",
        "\n",
        "def calculate_segment_f1(user_segments, model_segments):\n",
        "    tp = 0\n",
        "    for m_seg in model_segments:\n",
        "        m_range = set(expand_segment(m_seg))\n",
        "        for u_seg in user_segments:\n",
        "            u_range = set(expand_segment(u_seg))\n",
        "            if m_range & u_range:\n",
        "                tp += 1\n",
        "                break\n",
        "    precision = tp / len(model_segments) if model_segments else 0\n",
        "    recall = tp / len(user_segments) if user_segments else 0\n",
        "    f1 = 2 * precision * recall / (precision + recall) if precision + recall else 0\n",
        "    return f1, precision, recall\n",
        "\n",
        "def detect_kts_segments(features, penalty=500):\n",
        "    algo = rpt.KernelCPD(kernel=\"linear\").fit(features)\n",
        "    cps = algo.predict(pen=penalty)\n",
        "    segments, start = [], 0\n",
        "    for cp in cps:\n",
        "        segments.append((start, cp - 1))\n",
        "        start = cp\n",
        "    if segments[-1][1] < features.shape[0] - 1:\n",
        "        segments.append((start, features.shape[0] - 1))\n",
        "    return segments\n",
        "\n",
        "def knapsack(values, weights, capacity):\n",
        "    n = len(values)\n",
        "    dp = [[0 for _ in range(int(capacity * 100) + 1)] for _ in range(n + 1)]\n",
        "    for i in range(1, n + 1):\n",
        "        for w in range(int(capacity * 100) + 1):\n",
        "            weight = int(weights[i - 1] * 100)\n",
        "            if weight <= w:\n",
        "                dp[i][w] = max(values[i - 1] + dp[i - 1][w - weight], dp[i - 1][w])\n",
        "            else:\n",
        "                dp[i][w] = dp[i - 1][w]\n",
        "    selected = []\n",
        "    w = int(capacity * 100)\n",
        "    for i in range(n, 0, -1):\n",
        "        if dp[i][w] != dp[i - 1][w]:\n",
        "            selected.append(i - 1)\n",
        "            w -= int(weights[i - 1] * 100)\n",
        "    return selected[::-1]\n",
        "\n",
        "# =====================================\n",
        "# 4Ô∏è‚É£ Paths and Settings\n",
        "# =====================================\n",
        "video_list = [\n",
        "    \"Jumps\", \"Base Jumping\", \"Air_Force_One\", \"Bearpark_climbing\", \"Bike Polo\",\n",
        "    \"Bus_in_Rock_Tunnel\", \"car_over_camera\", \"Car_railcrossing\", \"Cockpit_Landing\", \"Cooking\",\n",
        "    \"Eiffel Tower\", \"Excavators river crossing\", \"Fire Domino\", \"Kids_playing_in_leaves\",\n",
        "    \"Notre_Dame\", \"Paintball\", \"paluma_jump\", \"playing_ball\", \"Playing_on_water_slide\",\n",
        "    \"Saving dolphines\", \"Scuba\", \"St Maarten Landing\", \"Statue of Liberty\", \"Valparaiso_Downhill\"\n",
        "]\n",
        "\n",
        "FEATURES_DIR = \"/mnt/d/Mass Projects/Video_Summ/extracted_features/\"\n",
        "MAT_DIR = \"/mnt/d/Mass Projects/Video_Summ/mat/\"\n",
        "FPS = 25\n",
        "PENALTY = 500\n",
        "SUMMARY_EXCEL = \"/mnt/d/Mass Projects/Video_Summ/RESULTS/RESULTS/SUMME/selector_model_eval.xlsx\"\n",
        "\n",
        "# =====================================\n",
        "# 5Ô∏è‚É£ Evaluate Videos\n",
        "# =====================================\n",
        "with pd.ExcelWriter(SUMMARY_EXCEL, engine=\"xlsxwriter\") as writer:\n",
        "    summary_data = []\n",
        "\n",
        "    for VIDEO_NAME in video_list:\n",
        "        print(f\"\\n==============================\\nüöÄ Processing video: {VIDEO_NAME}\\n==============================\")\n",
        "\n",
        "        feats_path = os.path.join(FEATURES_DIR, f\"{VIDEO_NAME}.npy\")\n",
        "        mat_path = os.path.join(MAT_DIR, f\"{VIDEO_NAME}.mat\")\n",
        "        if not os.path.exists(feats_path) or not os.path.exists(mat_path):\n",
        "            print(\"‚ùå Missing files. Skipping...\")\n",
        "            continue\n",
        "\n",
        "        raw_feats = np.load(feats_path)\n",
        "        num_frames = raw_feats.shape[0]\n",
        "\n",
        "        seqs = []\n",
        "        for start in range(0, num_frames - SEQ_LEN + 1, SEQ_LEN):\n",
        "            seq = raw_feats[start:start + SEQ_LEN]\n",
        "            seqs.append(seq)\n",
        "        if not seqs:\n",
        "            continue\n",
        "        seqs = np.array(seqs, dtype=np.float32)\n",
        "\n",
        "        preds = selector.predict(seqs, verbose=0)\n",
        "        preds = preds.reshape(-1)[:num_frames]\n",
        "\n",
        "        imp_scores = (preds - preds.min()) / (preds.max() - preds.min() + 1e-8)\n",
        "\n",
        "        model_segments = detect_kts_segments(raw_feats, penalty=PENALTY)\n",
        "        segment_durations = [(end - start + 1) / FPS for start, end in model_segments]\n",
        "        segment_scores = [np.mean(imp_scores[start:end + 1]) for start, end in model_segments]\n",
        "\n",
        "        total_duration = num_frames / FPS\n",
        "        summary_duration = total_duration * 0.15\n",
        "        selected_indices = knapsack(segment_scores, segment_durations, summary_duration)\n",
        "        selected_model_segments = [model_segments[i] for i in selected_indices]\n",
        "\n",
        "        mat = scipy.io.loadmat(mat_path)\n",
        "        user_scores = mat['user_score']\n",
        "        num_users = user_scores.shape[1]\n",
        "        all_user_metrics = []\n",
        "\n",
        "        for u in range(num_users):\n",
        "            usr = user_scores[:, u]\n",
        "            nonzero_indices = np.where(usr > 0)[0]\n",
        "            user_segments = get_segments_from_indices(nonzero_indices.tolist())\n",
        "            f1, precision, recall = calculate_segment_f1(user_segments, selected_model_segments)\n",
        "            all_user_metrics.append((u + 1, f1, precision, recall))\n",
        "\n",
        "        df = pd.DataFrame(all_user_metrics, columns=[\"User\", \"F1 Score\", \"Precision\", \"Recall\"])\n",
        "        df.to_excel(writer, sheet_name=VIDEO_NAME[:31], index=False)\n",
        "\n",
        "        summary_data.append({\n",
        "            \"Video\": VIDEO_NAME,\n",
        "            \"KTS Segments\": len(model_segments),\n",
        "            \"Selected\": len(selected_model_segments),\n",
        "            \"Penalty\": PENALTY,\n",
        "            \"Min F1\": df[\"F1 Score\"].min(),\n",
        "            \"Avg F1\": df[\"F1 Score\"].mean(),\n",
        "            \"Max F1\": df[\"F1 Score\"].max(),\n",
        "            \"Min Precision\": df[\"Precision\"].min(),\n",
        "            \"Avg Precision\": df[\"Precision\"].mean(),\n",
        "            \"Max Precision\": df[\"Precision\"].max(),\n",
        "            \"Min Recall\": df[\"Recall\"].min(),\n",
        "            \"Avg Recall\": df[\"Recall\"].mean(),\n",
        "            \"Max Recall\": df[\"Recall\"].max(),\n",
        "        })\n",
        "\n",
        "        del seqs\n",
        "        gc.collect()\n",
        "        tf.keras.backend.clear_session()\n",
        "\n",
        "    pd.DataFrame(summary_data).to_excel(writer, sheet_name=\"Summary\", index=False)\n",
        "    print(f\"\\n‚úÖ All results saved to: {SUMMARY_EXCEL}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a80217ea",
      "metadata": {
        "id": "a80217ea"
      },
      "source": [
        "# SELECTOR - TVSUM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e636926",
      "metadata": {
        "id": "9e636926"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import scipy.io\n",
        "import ruptures as rpt\n",
        "import pandas as pd\n",
        "import gc\n",
        "\n",
        "# ===============================\n",
        "# 1Ô∏è‚É£ Define Selector Model\n",
        "# ===============================\n",
        "SEQ_LEN = 150\n",
        "FEATURE_DIM = 2048\n",
        "\n",
        "class Selector(tf.keras.Model):\n",
        "    def __init__(self, input_dim=2048, hidden_dim=512, **kwargs):\n",
        "        super(Selector, self).__init__(**kwargs)\n",
        "        self.bilstm = tf.keras.layers.Bidirectional(\n",
        "            tf.keras.layers.LSTM(hidden_dim, return_sequences=True, dtype=\"float32\")\n",
        "        )\n",
        "        self.output_layer = tf.keras.layers.TimeDistributed(\n",
        "            tf.keras.layers.Dense(1, activation='sigmoid', dtype=\"float32\")\n",
        "        )\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.bilstm(inputs)\n",
        "        return self.output_layer(x)\n",
        "\n",
        "\n",
        "# ===============================\n",
        "# 2Ô∏è‚É£ Load Trained Selector Weights\n",
        "# ===============================\n",
        "SELECTOR_WEIGHTS = \"/mnt/d/Mass Projects/Video_Summ/RESULTS/MODELS/selector_model.keras\"\n",
        "\n",
        "selector = Selector(input_dim=FEATURE_DIM, hidden_dim=512)\n",
        "dummy_input = tf.random.normal((1, SEQ_LEN, FEATURE_DIM))\n",
        "selector(dummy_input)  # build model before loading weights\n",
        "selector.load_weights(SELECTOR_WEIGHTS)\n",
        "print(\"\\n‚úÖ Selector weights loaded successfully\")\n",
        "\n",
        "# ===============================\n",
        "# 3Ô∏è‚É£ Helper Functions\n",
        "# ===============================\n",
        "def get_segments_from_indices(indices):\n",
        "    if not indices:\n",
        "        return []\n",
        "    indices = sorted(set(indices))\n",
        "    segments, start = [], indices[0]\n",
        "    for i in range(1, len(indices)):\n",
        "        if indices[i] != indices[i - 1] + 1:\n",
        "            segments.append((start, indices[i - 1]))\n",
        "            start = indices[i]\n",
        "    segments.append((start, indices[-1]))\n",
        "    return segments\n",
        "\n",
        "def expand_segment(seg):\n",
        "    return list(range(seg[0], seg[1] + 1))\n",
        "\n",
        "def calculate_segment_f1(user_segments, model_segments):\n",
        "    tp = 0\n",
        "    for m_seg in model_segments:\n",
        "        m_range = set(expand_segment(m_seg))\n",
        "        for u_seg in user_segments:\n",
        "            u_range = set(expand_segment(u_seg))\n",
        "            if m_range & u_range:\n",
        "                tp += 1\n",
        "                break\n",
        "    precision = tp / len(model_segments) if model_segments else 0\n",
        "    recall = tp / len(user_segments) if user_segments else 0\n",
        "    f1 = 2 * precision * recall / (precision + recall) if precision + recall else 0\n",
        "    return f1, precision, recall\n",
        "\n",
        "def detect_kts_segments(features, penalty=500):\n",
        "    algo = rpt.KernelCPD(kernel=\"linear\").fit(features)\n",
        "    cps = algo.predict(pen=penalty)\n",
        "    segments, start = [], 0\n",
        "    for cp in cps:\n",
        "        segments.append((start, cp - 1))\n",
        "        start = cp\n",
        "    if segments[-1][1] < features.shape[0] - 1:\n",
        "        segments.append((start, features.shape[0] - 1))\n",
        "    return segments\n",
        "\n",
        "def knapsack(values, weights, capacity):\n",
        "    n = len(values)\n",
        "    dp = [[0 for _ in range(int(capacity * 100) + 1)] for _ in range(n + 1)]\n",
        "    for i in range(1, n + 1):\n",
        "        for w in range(int(capacity * 100) + 1):\n",
        "            weight = int(weights[i - 1] * 100)\n",
        "            if weight <= w:\n",
        "                dp[i][w] = max(values[i - 1] + dp[i - 1][w - weight], dp[i - 1][w])\n",
        "            else:\n",
        "                dp[i][w] = dp[i - 1][w]\n",
        "    selected = []\n",
        "    w = int(capacity * 100)\n",
        "    for i in range(n, 0, -1):\n",
        "        if dp[i][w] != dp[i - 1][w]:\n",
        "            selected.append(i - 1)\n",
        "            w -= int(weights[i - 1] * 100)\n",
        "    return selected[::-1]\n",
        "\n",
        "\n",
        "# ===============================\n",
        "# 4Ô∏è‚É£ Paths and Settings\n",
        "# ===============================\n",
        "video_list = [\n",
        "    \"Jumps\", \"Base Jumping\", \"Air_Force_One\", \"Bearpark_climbing\", \"Bike Polo\",\n",
        "    \"Bus_in_Rock_Tunnel\", \"car_over_camera\", \"Car_railcrossing\", \"Cockpit_Landing\", \"Cooking\",\n",
        "    \"Eiffel Tower\", \"Excavators river crossing\", \"Fire Domino\", \"Kids_playing_in_leaves\",\n",
        "    \"Notre_Dame\", \"Paintball\", \"paluma_jump\", \"playing_ball\", \"Playing_on_water_slide\",\n",
        "    \"Saving dolphines\", \"Scuba\", \"St Maarten Landing\", \"Statue of Liberty\", \"Valparaiso_Downhill\"\n",
        "]\n",
        "\n",
        "FEATURES_DIR = \"/mnt/d/Mass Projects/Video_Summ/extracted_features/\"\n",
        "MAT_DIR = \"/mnt/d/Mass Projects/Video_Summ/mat/\"\n",
        "PENALTY = 500\n",
        "FPS = 25\n",
        "SUMMARY_EXCEL = \"/mnt/d/Mass Projects/Video_Summ/RESULTS/RESULTS/TVSUM/selector_model_eval.xlsx\"\n",
        "\n",
        "# ===============================\n",
        "# 5Ô∏è‚É£ Evaluate on All Videos\n",
        "# ===============================\n",
        "with pd.ExcelWriter(SUMMARY_EXCEL, engine=\"xlsxwriter\") as writer:\n",
        "    summary_data = []\n",
        "\n",
        "    for VIDEO_NAME in video_list:\n",
        "        print(f\"\\n==============================\\nüöÄ Processing video: {VIDEO_NAME}\\n==============================\")\n",
        "\n",
        "        feats_path = os.path.join(FEATURES_DIR, f\"{VIDEO_NAME}.npy\")\n",
        "        mat_path = os.path.join(MAT_DIR, f\"{VIDEO_NAME}.mat\")\n",
        "\n",
        "        if not os.path.exists(feats_path) or not os.path.exists(mat_path):\n",
        "            print(\"‚ùå Missing files. Skipping...\")\n",
        "            continue\n",
        "\n",
        "        raw_feats = np.load(feats_path)\n",
        "        num_frames = raw_feats.shape[0]\n",
        "\n",
        "        # Pad/crop sequences\n",
        "        seqs = []\n",
        "        for start in range(0, num_frames - SEQ_LEN + 1, SEQ_LEN):\n",
        "            seq = raw_feats[start:start + SEQ_LEN]\n",
        "            seqs.append(seq)\n",
        "        if not seqs:\n",
        "            continue\n",
        "        seqs = np.array(seqs, dtype=np.float32)\n",
        "\n",
        "        # Predict importance\n",
        "        preds = selector.predict(seqs, verbose=0)\n",
        "        preds = preds.reshape(-1)[:num_frames]\n",
        "        imp_scores = (preds - preds.min()) / (preds.max() - preds.min() + 1e-8)\n",
        "\n",
        "        # ========= Segmentation + Knapsack =========\n",
        "        model_segments = detect_kts_segments(raw_feats, penalty=PENALTY)\n",
        "        segment_durations = [(end - start + 1) / FPS for start, end in model_segments]\n",
        "        segment_scores = [np.mean(imp_scores[start:end + 1]) for start, end in model_segments]\n",
        "\n",
        "        total_duration = num_frames / FPS\n",
        "        summary_duration = total_duration * 0.15\n",
        "        selected_indices = knapsack(segment_scores, segment_durations, summary_duration)\n",
        "        selected_model_segments = [model_segments[i] for i in selected_indices]\n",
        "\n",
        "        # ========= Load User Annotations =========\n",
        "        mat = scipy.io.loadmat(mat_path)\n",
        "        user_scores = mat['user_score']\n",
        "        num_users = user_scores.shape[1]\n",
        "        all_user_metrics = []\n",
        "\n",
        "        for u in range(num_users):\n",
        "            usr = user_scores[:, u]\n",
        "            nonzero_indices = np.where(usr > 0)[0]\n",
        "            user_segments = get_segments_from_indices(nonzero_indices.tolist())\n",
        "            f1, precision, recall = calculate_segment_f1(user_segments, selected_model_segments)\n",
        "            all_user_metrics.append((u + 1, f1, precision, recall))\n",
        "\n",
        "        df = pd.DataFrame(all_user_metrics, columns=[\"User\", \"F1 Score\", \"Precision\", \"Recall\"])\n",
        "        df.to_excel(writer, sheet_name=VIDEO_NAME[:31], index=False)\n",
        "\n",
        "        summary_data.append({\n",
        "            \"Video\": VIDEO_NAME,\n",
        "            \"KTS Segments\": len(model_segments),\n",
        "            \"Selected\": len(selected_model_segments),\n",
        "            \"Penalty\": PENALTY,\n",
        "            \"Min F1\": df[\"F1 Score\"].min(),\n",
        "            \"Avg F1\": df[\"F1 Score\"].mean(),\n",
        "            \"Max F1\": df[\"F1 Score\"].max(),\n",
        "            \"Min Precision\": df[\"Precision\"].min(),\n",
        "            \"Avg Precision\": df[\"Precision\"].mean(),\n",
        "            \"Max Precision\": df[\"Precision\"].max(),\n",
        "            \"Min Recall\": df[\"Recall\"].min(),\n",
        "            \"Avg Recall\": df[\"Recall\"].mean(),\n",
        "            \"Max Recall\": df[\"Recall\"].max(),\n",
        "        })\n",
        "\n",
        "        del seqs\n",
        "        gc.collect()\n",
        "        tf.keras.backend.clear_session()\n",
        "\n",
        "    pd.DataFrame(summary_data).to_excel(writer, sheet_name=\"Summary\", index=False)\n",
        "    print(f\"\\n‚úÖ All results saved to: {SUMMARY_EXCEL}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e295e99a",
      "metadata": {
        "id": "e295e99a"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import h5py\n",
        "import ruptures as rpt\n",
        "import gc\n",
        "\n",
        "# ========= 1Ô∏è‚É£ Define and Register Selector & Custom Loss =========\n",
        "@tf.keras.utils.register_keras_serializable()\n",
        "def sparsity_loss(y_true, y_pred):\n",
        "    sigma = 0.7\n",
        "    return tf.abs(tf.reduce_mean(y_pred) - sigma)\n",
        "\n",
        "@tf.keras.utils.register_keras_serializable()\n",
        "class Selector(tf.keras.Model):\n",
        "    def __init__(self, input_dim=2048, hidden_dim=512, **kwargs):\n",
        "        super(Selector, self).__init__(**kwargs)\n",
        "        self.bilstm = tf.keras.layers.Bidirectional(\n",
        "            tf.keras.layers.LSTM(hidden_dim, return_sequences=True, dtype=\"float32\")\n",
        "        )\n",
        "        self.output_layer = tf.keras.layers.TimeDistributed(\n",
        "            tf.keras.layers.Dense(1, activation='sigmoid', dtype=\"float32\")\n",
        "        )\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.bilstm(inputs)\n",
        "        return self.output_layer(x)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\"input_dim\": 2048, \"hidden_dim\": 512})\n",
        "        return config\n",
        "\n",
        "# ========= 2Ô∏è‚É£ Load Trained Selector Model =========\n",
        "SELECTOR_PATH = \"/mnt/d/Mass Projects/Video_Summ/RESULTS/MODELS/selector_model.keras\"\n",
        "\n",
        "with tf.keras.utils.custom_object_scope({\"Selector\": Selector, \"sparsity_loss\": sparsity_loss}):\n",
        "    selector = tf.keras.models.load_model(SELECTOR_PATH, compile=False)\n",
        "\n",
        "print(\"\\n‚úÖ Selector model loaded successfully\")\n",
        "\n",
        "# ========= 3Ô∏è‚É£ Helper Functions =========\n",
        "def get_segments_from_indices(indices):\n",
        "    if not indices:\n",
        "        return []\n",
        "    indices = sorted(set(indices))\n",
        "    segments, start = [], indices[0]\n",
        "    for i in range(1, len(indices)):\n",
        "        if indices[i] != indices[i - 1] + 1:\n",
        "            segments.append((start, indices[i - 1]))\n",
        "            start = indices[i]\n",
        "    segments.append((start, indices[-1]))\n",
        "    return segments\n",
        "\n",
        "def expand_segment(seg):\n",
        "    return list(range(seg[0], seg[1] + 1))\n",
        "\n",
        "def calculate_segment_f1(user_segments, model_segments):\n",
        "    tp = 0\n",
        "    for m_seg in model_segments:\n",
        "        m_range = set(expand_segment(m_seg))\n",
        "        for u_seg in user_segments:\n",
        "            u_range = set(expand_segment(u_seg))\n",
        "            if m_range & u_range:\n",
        "                tp += 1\n",
        "                break\n",
        "    precision = tp / len(model_segments) if model_segments else 0\n",
        "    recall = tp / len(user_segments) if user_segments else 0\n",
        "    f1 = 2 * precision * recall / (precision + recall) if precision + recall else 0\n",
        "    return f1, precision, recall\n",
        "\n",
        "def detect_kts_segments(features, penalty=500):\n",
        "    algo = rpt.KernelCPD(kernel=\"linear\").fit(features)\n",
        "    cps = algo.predict(pen=penalty)\n",
        "    segments, start = [], 0\n",
        "    for cp in cps:\n",
        "        segments.append((start, cp - 1))\n",
        "        start = cp\n",
        "    if segments[-1][1] < features.shape[0] - 1:\n",
        "        segments.append((start, features.shape[0] - 1))\n",
        "    return segments\n",
        "\n",
        "def knapsack(values, weights, capacity):\n",
        "    n = len(values)\n",
        "    dp = [[0 for _ in range(int(capacity * 100) + 1)] for _ in range(n + 1)]\n",
        "    for i in range(1, n + 1):\n",
        "        for w in range(int(capacity * 100) + 1):\n",
        "            weight = int(weights[i - 1] * 100)\n",
        "            if weight <= w:\n",
        "                dp[i][w] = max(values[i - 1] + dp[i - 1][w - weight], dp[i - 1][w])\n",
        "            else:\n",
        "                dp[i][w] = dp[i - 1][w]\n",
        "    selected = []\n",
        "    w = int(capacity * 100)\n",
        "    for i in range(n, 0, -1):\n",
        "        if dp[i][w] != dp[i - 1][w]:\n",
        "            selected.append(i - 1)\n",
        "            w -= int(weights[i - 1] * 100)\n",
        "    return selected[::-1]\n",
        "\n",
        "# ========= 4Ô∏è‚É£ TVSum Dataset Paths =========\n",
        "FEATURES_DIR = \"/mnt/d/Mass Projects/Video_Summ/TVSUM/RandomSplit_Dataset/resnet_npy/extracted_features_25fps_videos\"\n",
        "MAT_FILE_PATH = \"/mnt/d/Mass Projects/Video_Summ/ydata-tvsum50-v1_1/ydata-tvsum50-matlab/matlab/ydata-tvsum50.mat\"\n",
        "EXCEL_OUT = \"/mnt/d/Mass Projects/Video_Summ/RESULTS/RESULTS/TVSUM/selector_model_tvsum_eval.xlsx\"\n",
        "FPS = 25\n",
        "PENALTY = 500\n",
        "SEQ_LEN = 150\n",
        "\n",
        "# ========= 5Ô∏è‚É£ Load TVSum .mat File =========\n",
        "with h5py.File(MAT_FILE_PATH, \"r\") as mat_data:\n",
        "    tvsum50_group = mat_data[\"tvsum50\"]\n",
        "\n",
        "    def decode_str(ref):\n",
        "        return \"\".join(map(chr, mat_data[ref][()].flatten())).replace(\"\\x00\", \"\")\n",
        "\n",
        "    video_names = [decode_str(ref) for ref in tvsum50_group[\"video\"][:, 0]]\n",
        "    user_annos = [mat_data[ref][:] for ref in tvsum50_group[\"user_anno\"][:, 0]]\n",
        "    nframes_list = [int(mat_data[ref][()][0, 0]) for ref in tvsum50_group[\"nframes\"][:, 0]]\n",
        "\n",
        "# ========= 6Ô∏è‚É£ Evaluate on All Videos =========\n",
        "with pd.ExcelWriter(EXCEL_OUT, engine=\"xlsxwriter\") as writer:\n",
        "    summary_data = []\n",
        "\n",
        "    for idx, video_name in enumerate(video_names):\n",
        "        print(f\"\\nüöÄ Evaluating video: {video_name}\")\n",
        "\n",
        "        feature_path = os.path.join(FEATURES_DIR, f\"{video_name}.npy\")\n",
        "        if not os.path.exists(feature_path):\n",
        "            print(f\"‚ùå Missing feature file: {video_name}\")\n",
        "            continue\n",
        "\n",
        "        raw_feats = np.load(feature_path)\n",
        "        num_frames = raw_feats.shape[0]\n",
        "\n",
        "        # Predict importance for sequences\n",
        "        seqs = []\n",
        "        for start in range(0, num_frames - SEQ_LEN + 1, SEQ_LEN):\n",
        "            seq = raw_feats[start:start + SEQ_LEN]\n",
        "            seqs.append(seq)\n",
        "        if not seqs:\n",
        "            continue\n",
        "        seqs = np.array(seqs, dtype=np.float32)\n",
        "        preds = selector.predict(seqs, verbose=0)\n",
        "        preds = preds.reshape(-1)[:num_frames]\n",
        "        imp_scores = (preds - preds.min()) / (preds.max() - preds.min() + 1e-8)\n",
        "\n",
        "        # KTS segmentation + knapsack\n",
        "        model_segments = detect_kts_segments(raw_feats, penalty=PENALTY)\n",
        "        segment_durations = [(end - start + 1) / FPS for start, end in model_segments]\n",
        "        segment_scores = [np.mean(imp_scores[start:end + 1]) for start, end in model_segments]\n",
        "\n",
        "        total_duration = num_frames / FPS\n",
        "        summary_duration = total_duration * 0.15\n",
        "        selected_indices = knapsack(segment_scores, segment_durations, summary_duration)\n",
        "        selected_model_segments = [model_segments[i] for i in selected_indices]\n",
        "\n",
        "        # Evaluate user annotations\n",
        "        user_scores = user_annos[idx]\n",
        "        num_users = user_scores.shape[0]\n",
        "        all_user_metrics = []\n",
        "\n",
        "        for u in range(num_users):\n",
        "            user_score = user_scores[u]\n",
        "            k = int(np.floor(num_frames * 0.15))\n",
        "            selected_indices = np.argsort(user_score)[-k:]\n",
        "            user_segments = get_segments_from_indices(selected_indices.tolist())\n",
        "\n",
        "            f1, precision, recall = calculate_segment_f1(user_segments, selected_model_segments)\n",
        "            all_user_metrics.append((u + 1, f1, precision, recall))\n",
        "\n",
        "        df = pd.DataFrame(all_user_metrics, columns=[\"User\", \"F1 Score\", \"Precision\", \"Recall\"])\n",
        "        df.to_excel(writer, sheet_name=video_name[:31], index=False)\n",
        "\n",
        "        summary_data.append({\n",
        "            \"Video\": video_name,\n",
        "            \"KTS Segments\": len(model_segments),\n",
        "            \"Selected\": len(selected_model_segments),\n",
        "            \"Min F1\": df[\"F1 Score\"].min(),\n",
        "            \"Avg F1\": df[\"F1 Score\"].mean(),\n",
        "            \"Max F1\": df[\"F1 Score\"].max(),\n",
        "            \"Min Precision\": df[\"Precision\"].min(),\n",
        "            \"Avg Precision\": df[\"Precision\"].mean(),\n",
        "            \"Max Precision\": df[\"Precision\"].max(),\n",
        "            \"Min Recall\": df[\"Recall\"].min(),\n",
        "            \"Avg Recall\": df[\"Recall\"].mean(),\n",
        "            \"Max Recall\": df[\"Recall\"].max(),\n",
        "        })\n",
        "\n",
        "        del seqs\n",
        "        gc.collect()\n",
        "        tf.keras.backend.clear_session()\n",
        "\n",
        "    pd.DataFrame(summary_data).to_excel(writer, sheet_name=\"Summary\", index=False)\n",
        "    print(f\"\\n‚úÖ All results saved to: {EXCEL_OUT}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a486a9f",
      "metadata": {
        "id": "7a486a9f"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "1b69cb59",
      "metadata": {
        "id": "1b69cb59"
      },
      "source": [
        "# PLot image of top 10 frames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "251beb27",
      "metadata": {
        "id": "251beb27"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import scipy.io\n",
        "import ruptures as rpt\n",
        "import pandas as pd\n",
        "import gc\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "# ========= 1. Load Model =========\n",
        "class BiLSTMAttentionModel(tf.keras.Model):\n",
        "    def __init__(self, feature_dim=2048, num_heads=8, lstm_units=128, **kwargs):\n",
        "        super(BiLSTMAttentionModel, self).__init__(**kwargs)\n",
        "        self.bilstm = tf.keras.layers.Bidirectional(\n",
        "            tf.keras.layers.LSTM(lstm_units, return_sequences=True))\n",
        "        self.attention = tf.keras.layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=feature_dim // num_heads)\n",
        "        self.reconstruction_layer = tf.keras.layers.TimeDistributed(\n",
        "            tf.keras.layers.Dense(feature_dim, activation=\"linear\"))\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.bilstm(inputs)\n",
        "        x = self.attention(x, x)\n",
        "        return self.reconstruction_layer(x)\n",
        "\n",
        "MODEL_PATH = \"/mnt/d/Mass Projects/Video_Summ/RESULTS/MODELS/bilstm_multi_2-heads_60k.keras\"\n",
        "with tf.keras.utils.custom_object_scope({\"BiLSTMAttentionModel\": BiLSTMAttentionModel}):\n",
        "    model = tf.keras.models.load_model(MODEL_PATH)\n",
        "print(\"\\n‚úÖ Model loaded successfully\")\n",
        "\n",
        "# ========= 2. Helper Functions =========\n",
        "def get_segments_from_indices(indices):\n",
        "    if not indices:\n",
        "        return []\n",
        "    indices = sorted(set(indices))\n",
        "    segments, start = [], indices[0]\n",
        "    for i in range(1, len(indices)):\n",
        "        if indices[i] != indices[i - 1] + 1:\n",
        "            segments.append((start, indices[i - 1]))\n",
        "            start = indices[i]\n",
        "    segments.append((start, indices[-1]))\n",
        "    return segments\n",
        "\n",
        "def expand_segment(seg):\n",
        "    return list(range(seg[0], seg[1] + 1))\n",
        "\n",
        "def calculate_segment_f1(user_segments, model_segments):\n",
        "    tp = 0\n",
        "    matched = []\n",
        "    for m_seg in model_segments:\n",
        "        m_range = set(expand_segment(m_seg))\n",
        "        for u_seg in user_segments:\n",
        "            u_range = set(expand_segment(u_seg))\n",
        "            if m_range & u_range:\n",
        "                tp += 1\n",
        "                matched.append(m_seg)\n",
        "                break\n",
        "    precision = tp / len(model_segments) if model_segments else 0\n",
        "    recall = tp / len(user_segments) if user_segments else 0\n",
        "    f1 = 2 * precision * recall / (precision + recall) if precision + recall else 0\n",
        "    return f1, precision, recall, matched\n",
        "\n",
        "def detect_kts_segments(features, penalty=500):\n",
        "    algo = rpt.KernelCPD(kernel=\"linear\").fit(features)\n",
        "    change_points = algo.predict(pen=penalty)\n",
        "    change_points = [int(cp) for cp in change_points]\n",
        "    scene_segments = []\n",
        "    start_frame = 0\n",
        "    for cp in change_points:\n",
        "        scene_segments.append((start_frame, cp - 1))\n",
        "        start_frame = cp\n",
        "    if scene_segments[-1][1] < features.shape[0] - 1:\n",
        "        scene_segments.append((start_frame, features.shape[0] - 1))\n",
        "    return scene_segments\n",
        "\n",
        "def knapsack(values, weights, capacity):\n",
        "    n = len(values)\n",
        "    dp = [[0 for _ in range(int(capacity * 100) + 1)] for _ in range(n + 1)]\n",
        "    for i in range(1, n + 1):\n",
        "        for w in range(int(capacity * 100) + 1):\n",
        "            weight = int(weights[i - 1] * 100)\n",
        "            if weight <= w:\n",
        "                dp[i][w] = max(values[i - 1] + dp[i - 1][w - weight], dp[i - 1][w])\n",
        "            else:\n",
        "                dp[i][w] = dp[i - 1][w]\n",
        "    selected = []\n",
        "    w = int(capacity * 100)\n",
        "    for i in range(n, 0, -1):\n",
        "        if dp[i][w] != dp[i - 1][w]:\n",
        "            selected.append(i - 1)\n",
        "            w -= int(weights[i - 1] * 100)\n",
        "    return selected[::-1]\n",
        "\n",
        "# ========= 3. Process Videos =========\n",
        "video_list = [\n",
        "    \"Jumps\", \"Base Jumping\", \"Air_Force_One\", \"Bearpark_climbing\", \"Bike Polo\",\n",
        "    \"Bus_in_Rock_Tunnel\", \"car_over_camera\", \"Car_railcrossing\", \"Cockpit_Landing\", \"Cooking\",\n",
        "    \"Eiffel Tower\", \"Excavators river crossing\", \"Fire Domino\", \"Kids_playing_in_leaves\",\n",
        "    \"Notre_Dame\", \"Paintball\", \"paluma_jump\", \"playing_ball\", \"Playing_on_water_slide\",\n",
        "    \"Saving dolphines\", \"Scuba\", \"St Maarten Landing\", \"Statue of Liberty\", \"Valparaiso_Downhill\"\n",
        "]\n",
        "\n",
        "FEATURES_DIR = \"/mnt/d/Mass Projects/Video_Summ/extracted_features/\"\n",
        "MAT_DIR = \"/mnt/d/Mass Projects/Video_Summ/mat/\"\n",
        "FRAME_DIR = \"/mnt/d/Mass Projects/Video_Summ/video_frames\"\n",
        "CHUNK_SIZE = 500\n",
        "PENALTY = 500\n",
        "FPS = 25\n",
        "SUMMARY_EXCEL = \"/mnt/d/Mass Projects/Video_Summ/RESULTS/RESULTS/SUMME/delete.xlsx\"\n",
        "\n",
        "with pd.ExcelWriter(SUMMARY_EXCEL, engine=\"xlsxwriter\") as writer:\n",
        "    summary_data = []\n",
        "\n",
        "    for VIDEO_NAME in video_list:\n",
        "        print(f\"\\n==============================\\nüöÄ Processing video: {VIDEO_NAME}\\n==============================\")\n",
        "\n",
        "        feats_path = os.path.join(FEATURES_DIR, f\"{VIDEO_NAME}.npy\")\n",
        "        mat_path = os.path.join(MAT_DIR, f\"{VIDEO_NAME}.mat\")\n",
        "        if not os.path.exists(feats_path) or not os.path.exists(mat_path):\n",
        "            print(\"‚ùå Skipping, missing file.\")\n",
        "            continue\n",
        "\n",
        "        raw_feats = np.load(feats_path)\n",
        "        num_frames = raw_feats.shape[0]\n",
        "        video_feats = raw_feats[np.newaxis, ...]\n",
        "\n",
        "        recon = np.zeros_like(video_feats)\n",
        "        for i in range((num_frames + CHUNK_SIZE - 1) // CHUNK_SIZE):\n",
        "            s, e = i * CHUNK_SIZE, min((i + 1) * CHUNK_SIZE, num_frames)\n",
        "            recon[:, s:e, :] = model.predict(video_feats[:, s:e, :], verbose=0)\n",
        "        print(\"‚úÖ Features reconstructed\")\n",
        "\n",
        "        errs = np.mean(np.abs(video_feats - recon), axis=2).flatten()\n",
        "        imp_scores = (errs - errs.min()) / (errs.max() - errs.min())\n",
        "\n",
        "        model_segments = detect_kts_segments(raw_feats, penalty=PENALTY)\n",
        "        segment_durations = [(end - start + 1) / FPS for start, end in model_segments]\n",
        "        segment_scores = [np.mean(imp_scores[start:end + 1]) for start, end in model_segments]\n",
        "\n",
        "        total_duration = num_frames / FPS\n",
        "        summary_duration = total_duration * 0.15\n",
        "        selected_indices = knapsack(segment_scores, segment_durations, summary_duration)\n",
        "        selected_model_segments = [model_segments[i] for i in selected_indices]\n",
        "\n",
        "        mat = scipy.io.loadmat(mat_path)\n",
        "        user_scores = mat['user_score']\n",
        "        num_users = user_scores.shape[1]\n",
        "        all_user_metrics = []\n",
        "\n",
        "        for u in range(num_users):\n",
        "            usr = user_scores[:, u]\n",
        "            nonzero_indices = np.where(usr > 0)[0]\n",
        "            user_segments = get_segments_from_indices(nonzero_indices.tolist())\n",
        "\n",
        "            f1, precision, recall, _ = calculate_segment_f1(user_segments, selected_model_segments)\n",
        "            all_user_metrics.append((u + 1, f1, precision, recall))\n",
        "\n",
        "        df = pd.DataFrame(all_user_metrics, columns=[\"User\", \"F1 Score\", \"Precision\", \"Recall\"])\n",
        "        df.to_excel(writer, sheet_name=VIDEO_NAME[:31], index=False)\n",
        "\n",
        "        summary_data.append({\n",
        "            \"Video Name\": VIDEO_NAME,\n",
        "            \"KTS Segments\": len(model_segments),\n",
        "            \"Knapsack Selected\": len(selected_model_segments),\n",
        "            \"Penalty\": PENALTY,\n",
        "            \"Min Precision\": df[\"Precision\"].min(),\n",
        "            \"Avg Precision\": df[\"Precision\"].mean(),\n",
        "            \"Max Precision\": df[\"Precision\"].max(),\n",
        "            \"Min Recall\": df[\"Recall\"].min(),\n",
        "            \"Avg Recall\": df[\"Recall\"].mean(),\n",
        "            \"Max Recall\": df[\"Recall\"].max(),\n",
        "            \"Min F1\": df[\"F1 Score\"].min(),\n",
        "            \"Avg F1\": df[\"F1 Score\"].mean(),\n",
        "            \"Max F1\": df[\"F1 Score\"].max(),\n",
        "        })\n",
        "\n",
        "        # ============================ #\n",
        "        # üì∏ Plot Top Frames from Model #\n",
        "        # ============================ #\n",
        "        TOP_N = 10\n",
        "        top_idxs = sorted(np.argsort(imp_scores)[-TOP_N:])\n",
        "\n",
        "        fig, axs = plt.subplots(1, TOP_N, figsize=(20, 3))\n",
        "        fig.suptitle(f\"Top {TOP_N} Frames Selected by Model - {VIDEO_NAME}\", y=1.05)\n",
        "\n",
        "        for i, idx in enumerate(top_idxs):\n",
        "            frame_path = os.path.join(FRAME_DIR, VIDEO_NAME, f\"frame_{idx}.jpg\")\n",
        "            if os.path.exists(frame_path):\n",
        "                img = Image.open(frame_path)\n",
        "                axs[i].imshow(img)\n",
        "                axs[i].set_title(f\"Frame {idx}\", fontsize=8)\n",
        "                axs[i].axis(\"off\")\n",
        "            else:\n",
        "                axs[i].axis(\"off\")\n",
        "                axs[i].set_title(f\"Missing {idx}\", fontsize=8)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        del video_feats, recon\n",
        "        gc.collect()\n",
        "        tf.keras.backend.clear_session()\n",
        "\n",
        "    pd.DataFrame(summary_data).to_excel(writer, sheet_name=\"Summary\", index=False)\n",
        "    print(f\"\\n‚úÖ All results saved to: {SUMMARY_EXCEL}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "810a1525",
      "metadata": {
        "id": "810a1525"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "# ============================\n",
        "# üîπ User Inputs\n",
        "# ============================\n",
        "VIDEO_NAME = \"Fire Domino\"  # change to your video name\n",
        "FRAME_DIR = \"/mnt/d/Mass Projects/Video_Summ/video_frames\"\n",
        "\n",
        "# üîπ Manually specify frame indices to plot\n",
        "# (example: top 10 frames you want)\n",
        "manual_frames = [120, 350, 460, 800, 950, 1120, 1300, 1346, 1364, 1450]\n",
        "\n",
        "# ============================\n",
        "# üîπ Plotting\n",
        "# ============================\n",
        "fig, axs = plt.subplots(1, len(manual_frames), figsize=(20, 3))\n",
        "fig.suptitle(f\"Top {len(manual_frames)} Frames Selected by Model - {VIDEO_NAME}\", y=1.05)\n",
        "\n",
        "for i, idx in enumerate(manual_frames):\n",
        "    frame_path = os.path.join(FRAME_DIR, VIDEO_NAME, f\"frame_{idx}.jpg\")\n",
        "    if os.path.exists(frame_path):\n",
        "        img = Image.open(frame_path)\n",
        "        axs[i].imshow(img)\n",
        "        axs[i].set_title(f\"Frame {idx}\", fontsize=8)\n",
        "        axs[i].axis(\"off\")\n",
        "    else:\n",
        "        axs[i].axis(\"off\")\n",
        "        axs[i].set_title(f\"Missing {idx}\", fontsize=8)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae2f797a",
      "metadata": {
        "id": "ae2f797a"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "# ============================\n",
        "# üîπ User Inputs\n",
        "# ============================\n",
        "VIDEO_NAME = \"Saving dolphines\"  # change to your video name\n",
        "FRAME_DIR = \"/mnt/d/Mass Projects/Video_Summ/video_frames\"\n",
        "\n",
        "# üîπ Manually specify frame indices to plot\n",
        "# (example: top 10 frames you want)\n",
        "manual_frames = [1544, 1598, 1839, 2970, 3527, 4008, 4326, 5064, 6097, 6518]\n",
        "\n",
        "# ============================\n",
        "# üîπ Plotting\n",
        "# ============================\n",
        "fig, axs = plt.subplots(1, len(manual_frames), figsize=(20, 3))\n",
        "fig.suptitle(f\"Top {len(manual_frames)} Frames Selected by Model - {VIDEO_NAME}\", y=1.05)\n",
        "\n",
        "for i, idx in enumerate(manual_frames):\n",
        "    frame_path = os.path.join(FRAME_DIR, VIDEO_NAME, f\"frame_{idx}.jpg\")\n",
        "    if os.path.exists(frame_path):\n",
        "        img = Image.open(frame_path)\n",
        "        axs[i].imshow(img)\n",
        "        axs[i].set_title(f\"Frame {idx}\", fontsize=8)\n",
        "        axs[i].axis(\"off\")\n",
        "    else:\n",
        "        axs[i].axis(\"off\")\n",
        "        axs[i].set_title(f\"Missing {idx}\", fontsize=8)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66891d74",
      "metadata": {
        "id": "66891d74"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "TF",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}